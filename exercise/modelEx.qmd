---
title: Forest Modeling Exercise
subtitle: Process-based and empirical modeling group assignments
format:
  titlepage-pdf:
    documentclass: scrbook
    classoption: ["oneside", "open=any"]
    number-sections: true
    toc: true
    titlepage: "bg-image"
    titlepage-bg-image: ""
    titlepage-logo: "images/logo3.jpg"
    titlepage-header: "The Publisher"
    titlepage-footer: |
      Interdisciplinary Summer School
      Ljubljana 2023
      [Repository available in GitHub](https://github.com/oldiya/summerSchoolExercise)
author:
  - name: Olalla Díaz-Yáñez
    affiliations:
      - name: olalla.diaz@usys.ethz.ch (ETH Zurich)
  - name: Laura Dobor 
    affiliations:
      - name: laura.dobor@gmail.com (CZU)
  - name: Katarina Merganicova
    affiliations:
      - name: merganicova@fld.czu.cz (CZU)
  - name: Mats Nieberg
    affiliations:
      - name: mats.nieberg@pik-potsdam.de (PIK-Potsdam | EFI)
bibliography: bibliography.bib  
---

```{r not to show, echo=FALSE}
  # To export to html for the web 
  # html:
   #  toc: true
   #  toc-depth: 3
   #  toc-location: left
```

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(fields)
library(RSQLite)
library(tidyverse)
library(gridExtra)   

library(cowplot)
library(openxlsx)
library(truncnorm)
library(adiv)
```

# Overview {#sec-overview}

This document contains the instructions of the modeling group assignments. It contains a section for the process model approach and a different section for the empirical modelling.

This document describes all the exercises, but your group has been assigned to only one, including one specific modeling approach. Each group has two questions to be answered (one question per subgroup inside each group). Please get in touch with your group coach if you are unsure what section you should focus on. The table below summarizes and links to the different parts of this document:

| Group | Subgroup Question | Question                                                                                                    | Approach | Go to    |
|---------------|---------------|---------------|---------------|---------------|
| 1     | A                 |                                                                                                             | iLand    | @sec-A_1 |
| 1     | B                 |                                                                                                             | iLand    | @sec-A_2 |
| 1     | C                 | Does a more diverse forest in structure and composition have more Bryophites species?                       | GLM      | @sec-C_1 |
| 1     | D                 | Is the number of Bryophites species affected by forest management type and the forest structural diversity? | GLM      | @sec-D_1 |
| 2     | A                 |                                                                                                             | iLand    | @sec-A_2 |
| 2     | B                 |                                                                                                             | iLand    | @sec-B_2 |
| 2     | C                 | Does a more diverse forest in structure and composition have more bird species?                             | GLM      | @sec-C_2 |
| 2     | D                 | Is the number of bird species affected by forest management type and the forest structural diversity?       | GLM      | @sec-D_2 |
| 3     | A                 |                                                                                                             | iLand    | @sec-A_3 |
| 3     | B                 |                                                                                                             | iLand    | @sec-B_3 |
| 3     | C                 | Is the presence of the Great spotted woodpecker affected by forest density?                                 | BRT      | @sec-C_3 |
| 3     | D                 | Is the presence of the Great spotted woodpecker affected by forest diversity?                               | BRT      | @sec-D_3 |
| 4     | A                 |                                                                                                             | iLand    | @sec-A_4 |
| 4     | B                 |                                                                                                             | iLand    | @sec-B_4 |
| 4     | C                 | Is the presence of the Eurasian treecreeper affected by forest density?                                     | BRT      | @sec-C_4 |
| 4     | D                 | Is the presence of the Eurasian treecreeper affected by forest management?                                  | BRT      | @sec-D_4 |

## Data and model

We provide all data, model and scripts for the excercises. However if you will use the model iLand for your research please get in contact with the model developers at the Technical University Münich: Werner Rammer (werner.rammer\@tum.de) and Rupert Seidl (rupert.seidl\@tum.de). Regarding the biodiversity data used in the empirical modeling processed in the emprical modeling part, in case of further usage please contact Jeňýk Hofmeister at the Czech University of Life Sciences Prague (jenyk.hofmeister\@email.cz).

# Process based

## iLand model

### General

iLand is an ecosystem model that simulates forest landscape dynamics, including growth and regeneration, disturbance dynamics, and management in a spatially explicit manner. The main entity in the model is a tree, for which the demographic processes are simulated. Processes at the stand and landscape scale constrain the dynamics of individual trees and thus allow for the scaling of tree-scale processes to large areas. The model explicitly simulates tree competition for resources such as light, water, and nutrients. A light use efficiency approach is used to simulate the production physiology. Carbon starvation is used as a process oriented indicator of tree stress, which can result from competition for resources as well as suboptimal environmental conditions for tree growth (e.g., drought).

iLand's mechanistic representation of forest disturbances and vegetation dynamics, as well as the climatic sensitivity of these processes, makes it well suited for the research of disturbance dynamics under climate change. Additionally, flexible implementation of management operations, which include planting after harvests or natural disturbances, thinning, harvesting, and post-disturbance salvaging, allows for testing the effects of various disturbance management strategies.

A detailed model documentation is availabe on iLand WIKI page: https://iland-model.org/iLand+Hub

### Input and outputs of iLand

iLand needs information in specific formats about environment (mainly climate and soil) and trees. Daily climate data is needed (https://iland-model.org/ClimateData) for minimum, maximum temperature, precipitation, vapor pressure deficit and radiation. Soil depth and soil texture (sand, silt, clay %) information are needed. The soil is represented as a one-layer bucket, no depth-dependent information is needed. The model needs species-specific parameters (https://iland-model.org/species+parameter) that are describing the behavior of each tree species (growth, mortality, competition etc.). Currently there are 31 species parametrizied for iLand, and the species specific parameters are stored in a database that is an input for the model. The parameters were previously calibrated for European conditions (species_param_europe.sqlite). iLand uses short codes for species derived from the latin names (e.g. Picea Abies - piab, Fagus Sylvatica - fasy, ..) Information on the initial forest is also required to start a simulation.

As iLand is a landscape scale model, both climate, soil and tree information need to be set spatially. For larger areas environmental maps can be set using a 100x100m resolution grid, a so called resource grid with resource units, and tree information can be set by maximum 10x10m resolution grid on a stand grid using stand IDs. There are more options how to initialize a landscape in iLand depending on our spatial scales and available data (https://iland-model.org/initialization).

In our case now we will use iLand in a stand-scale mode (called torus), where we simulate only one 100x100m pixel, 1 ha forest area. We will use single-tree initialization method, where we set the x-y coordinates of the trees inside the 100x100m area, tree species, dbh and height of each tree. From inventory we have data for the a circle with 13.82m radius. We generated trees for the 1ha area based on the plot-data. See details later.

The output of the model is an sqlite database file. The output produced by the models is highly versatile and need to be set in advance of the simulation which output tables we would like to get.

### How to work with the model

Simulations are driven by one xml file, the project file. After starting iland.exe, we should call the project file, load the initial forest and then run the simulation for the required lenght of period. iLand comes with a graphical interface where you can visualise single trees and many other things: https://iland-model.org/iLand+viewer

## Excercises

Your group will work with the plot which you measured and worked with in the previous days (Plot1-Plot4). The 2 process based subgroups will do the same modeling experiment, just addressing different questions based on the results (see the 2 questions below).

You will simulate the growth and development using the process-based model, iLand. The task is to simulate your study plot for 100 years under reference conditions and one/two simplified scenarios that you could define upon your ideas. You can define scenarios assuming different temperature, precipitation and CO2 concentration levels (see more details how to do it later below). The questions that you should address forming 2 sub-groups are the following:

A)  How biodiversity indices are changing in time and across the simulated scenario(s)? (Calculate indices)

B)  How the species distribution and total living biomass C content changing in time? Compare 0 year and 100 year status in the reference case and in the case of your scenario(s)!

### Getting started

Navigate to this folder and download the materials for the process-based modeling exercise: https://drive.google.com/drive/folders/1o2_K3ZN-SnPR44UzZoHj9lFZQu-vU3wg?usp=drive_link

Go to the *iLand_simulations* folder. Here you will find several folders that are the part of the model, others are containing input data for the model and one folder is dedicated for the outputs. Additionally, you will find *iland.exe* and *.xml* files. The *.xml* file is called *project file*. This file is driving the settings of simulations, such as input/output file names, output variables and many other settings. This file is what you need to run in the model.

The xml file structure follows a tree structure, e.g:

```{r eval=FALSE, message = FALSE, warning=FALSE}
<root>
 <child>
 <subchild>
 ...
 </subchild>
 </child>
</root> 
```

The iLand project file consists of five main sections:

-   system: settings like file path, database locations, or logging
-   model:main settings of the models: extent (world), site specific setting, used climate, model initialization and management
-   modules: settings related to the disturbance modules of iLand
-   output: definition of which outputs should be created by the model
-   user: this section can be used for user-defined settings

More details about the project file structure and meaning of each record can be found here: https://iland-model.org/project+file

We prepared one project file for each group (for each simulation plot). You can right away run it, and then copy-paste and modify it to specify your own scenarios for alternative simulations. You can open a project file in any text editor, but we recommend to use Notepad++ for this (https://notepad-plus-plus.org/downloads/).

### Explore input files

The following input files are needed and prepared for you to run the model: This is all prepared, YOU DO NOT HAVE TO CHANGE ANYTHING:

-   Species parameter file: database/species_param_europe.sqlite Containing the parameters for each species that are driving growth, mortality, establishment and other processes. https://iland-model.org/species+parameter

Set in project file:

```{r ex1, eval=FALSE, message = FALSE, warning=FALSE}

 <path>
 <home></home>
 <database>database</database> <!-------- HERE 
      <lip>lip</lip>
      <temp>temp</temp>
      <script>scripts</script>
	  <init>init</init>
	  <output>output</output>
    </path>
    …
     <database>
      <in>species_param_europe.sqlite</in>                  <!-------- HERE 
      <out>Output_plot1_4deg_30percdrier.sqlite</out>        
      <climate>E-OBSv27_Roznik_46.05_14.45_1961-1990.sqlite</climate>
    </database>
    
```

-   Climate file: database/E-OBSv27_Roznik_46.05_14.45_1961-1990.sqlite\
    Daily climate data for the area based on the E-OBS dataset. https://iland-model.org/ClimateData https://surfobs.climate.copernicus.eu/dataaccess/access_eobs.php#datafiles We are using the same climate input for all plots. The E-OBS data is representative for a 0.1x0.1 degree resolution gridbox

Set in project file:

```{r ex2, eval=FALSE, message = FALSE, warning=FALSE}
     <database>
      <in>species_param_europe.sqlite</in>                  
      <out>Output_plot1_4deg_30percdrier.sqlite</out>        
      <climate>E-OBSv27_Roznik_46.05_14.45_1961-1990.sqlite</climate> <!---- HERE
    </database>
```

-   Enviromental file: gis/Environment.txt\
    The structure of this file is very flexible, more or less columns can be set. If we would have a landscape with larger area with different environments, we could set more lines into this file. For now we have only one simulation pixel with 1ha area. Here we set which climate table to use from the climate file (there could be more tables, but now we have only one), what is the soil texture, soil depth. The column names are referring to specific lines in the project file.

For example: if we set here "model.site.pctSand", the model will use this sand % value instead of the value that we have in the project file under:

```{r ex3, eval=FALSE, message = FALSE, warning=FALSE}
  <model>   
    …
        <site>
              <availableNitrogen>84</availableNitrogen> <!-- kg/ha/yr -->
	 <soilDepth>38</soilDepth> <!-- in cm -->
	 <pctSand>9</pctSand> 
	 <pctSilt>53</pctSilt> 
	 <pctClay>38</pctClay> 
 ...
 </site>
 ...
 </model>
 
```

Set in project file:

```{r ex4, eval=FALSE, message = FALSE, warning=FALSE}

	 <environmentGrid>gis/environment_grid.asc</environmentGrid>
	 <environmentFile>gis/Environment.txt</environmentFile> <!---- HERE
```

-   Environment grid: gis/environment_grid.asc This would specify the map of different environments. Now we have only 1 pixel, with the id of 1. In the previous file we had also id column, this specifys we want to use that environment for our pixel.

Set in project file:

```{r ex5, eval=FALSE, message = FALSE, warning=FALSE}

	 <environmentGrid>gis/environment_grid.asc</environmentGrid> <!---- HERE
	 <environmentFile>gis/Environment.txt</environmentFile> 
```

-   Tree initialization file: init/Tree_init_plot_1.txt This is the list of the tree with x,y coordinates, species, dbh, height and optionally with age. (age=0 means, there is no data on age, model will generate) There are other options to set initial trees/landscape (e.g. using distributions, number of trees in a given dbh range, or using outputs of another simulation) More details: https://iland-model.org/initialize+trees

```{r ex6, eval=FALSE, message = FALSE, warning=FALSE}
	 <initialization>
	 <type>single</type>
	 <mode>unit</mode> 
	 ...
 <file>Tree_init_plot_1.txt</file> <!---- HERE
	 <saplingFile></saplingFile>
 ...
 </initialization>
```

Here we initialize trees taller than 4 meters. Trees smaller than 4m are handled as sapling cohorts in separated input file. Now we do not put there saplings and we do not have a sapling file.

NOTE: in the graphical interface you also wont see trees smaller than 4m, because they are not simulated as individuals rather in cohorts. But as regeneration will work, after a while as they grow above 4m, they become individual trees and we can see them also visually and they have own properties (dbh, height, age,...https://iland-model.org/tree+variables ). More details on saplings: https://iland-model.org/sapling+growth+and+competition

Setting the output tables: In the output section you can set which tables you want to enable. Here you can find more info on the structure and variables of each table: https://iland-model.org/Outputs

To answer the questions the most straight forward way is to look the *landscape* output and use the *total_carbon_kg* column (total carbon in living biomass (aboveground compartments and roots) of all living trees (including regeneration layer) (kg/ha) ). This output table aggregates on the level of landscape x species. Values are always aggregated per hectare. The output is created after the growth of the year. We pre-set the project file to have this output. Additionally we will work with the *tree* output, where individual trees are recorded with position.

```{r ex7, eval=FALSE, message = FALSE, warning=FALSE}

 <output>
 
 <tree>
 <enabled>true</enabled>
 </tree>
 
 ...
 
 <landscape>
 <enabled>true</enabled>
 </landscape>

 
 </output>
 
```

### Run the model

-   Double click on iland.exe and wait until the graphical interface opens.
-   Load the required project file on the left-hand-side under *iLand project file* by browsing on your computer after clicking on the folder icon next to the box.
-   After you selected a project file, click on the "Create Model" on the top-left part of the window with an icon of a Globe.
-   Wait until the simulation area shown in the middle.
-   Try out some visualizations on the right hand-side \*Visualisation options". e.g individual trees + color by species. Here you can explore the initial stage of the 1 ha simulation area.
-   To run the model click on Run Model icon on the top and give 100 years to simulate.
-   On the bottom of the window you can follow how fast the model is running and see if it is finished.
-   Stage of the last year remains in the simulation area, and you can go to the folder *output* to check your output file.

### Working with the output:

The output database has a *.sqlite* extension. You can explore outputs:

-   Open and browse it in the *DB Browser* software that was on the software list. (https://sqlitebrowser.org/)
-   Load the file into R, where you can make additional data analyses needed to answer the questions in the exercise. Here you can use the library *RSQLite* see below:

```{r ex8, eval=FALSE, message = FALSE, warning=FALSE}

library(RSQLite)

file<-"../iLand_simulations/output/Output_plot1.sqlite"

 sqlite.driver <- dbDriver("SQLite")
 db1 <- dbConnect(sqlite.driver, dbname = file) # connect to the file
 tabs <-dbListTables(db1) # explore the tables in the file
 print(tabs)

 landscape <- dbReadTable(db1,"landscape")

 dbDisconnect(db1)
 
 summary(landscape)
 head(landscape)
```

There are different output tables in iLand and all have specific structure, column and spatial representation of the records. The landscape output gives information on the whole landscape, but here we will work with one 1 ha pixel that is our "whole" landscape for now. Here species specific information is also available for each year. More about the meaning of the columns in the landscape output you can find here: https://iland-model.org/Outputs#Landscape_aggregates_per_species Not always all outputs are produced, in the project file we can set which output tables we want to enable, and those will be created.

### Run alternative scenarios

The prepared simulation is using the 30years climate of 1961-1990, and repeating during the simulation. (The model copy paste the 30year time series after each other to fill up the simulation period) For CO2 concentration 400ppm is given. Your task is to run 2 extra alternative scenarios where you modify the output data. For example assuming 800ppm, and 4degree warming, or keep CO2 on 400ppm and decrease precipitation by 20%.

All of these modification can be done in the project file directly, you do not need to modify input data files!

For this, go to the climate section and modify the values there, and save as the project file as your alternative scenario.

```{r ex9, eval=FALSE, message = FALSE, warning=FALSE}

 <climate> 
 <co2concentration>400</co2concentration> <!-------- HERE 
 	 <tableName>Roznik</tableName>
 <batchYears>30</batchYears> 
	 <temperatureShift>4</temperatureShift> <!-------- HERE 
	 <precipitationShift>0.8</precipitationShift> <!-------- HERE 
	 <randomSamplingEnabled>false</randomSamplingEnabled>
		 <randomSamplingList></randomSamplingList> 
 </climate>

```

Note that the same CO2 concentration will be used during the whole simulation period (there is a possibility to give annually changing CO2 concentration using an external file, but for now we won't use it for simplicity). The temperature shift is applied by the model on each day's temperature values. The precipitation shift is a scaler that the model applies on each day's precipitation amount. (0.8 gives 20% decrease)

DO NOT FORGET TO CHANGE THE OUTPUT FILE NAME AS WELL for your alternative scenario, otherwise it will overwrite the previous output. You can do it in this section in the beginning of the project file:

```{r ex10, eval=FALSE, message = FALSE, warning=FALSE}

 <database>
 <in>species_param_europe.sqlite</in> 
 <out>Output_plot1_4deg_20percdrier.sqlite</out> <!-------- HERE 
 <climate>E-OBSv27_Roznik_46.05_14.45_1961-1990.sqlite</climate>
 </database>
```

Running the alternative scenario follows the same steps as before.

### Question A - Group 1 {#sec-A_1}

-   How biodiversity indices are changing in time and across the simulated scenario(s) on Plot 1?

Run the model as it is described in the previous chapters to have at least 2 simulations completed: one with reference conditions and one scenarios with some changes in the environment. Check if you have the output files in the output folder: *iLand_simulations/output/*. If you manage to simualate 2 scenarios, you can expand the code to have file3, and 3rd from each variable, or make the comparison in 2 step always comparing one scenario to the reference conditions at the time.

Open the *summerSchoolExerciseProcessBased.Rproj* project in R studio and start working there.

Read in the *tree* output table from two outputs you have for your plot:

```{r ex11, eval=TRUE, message = FALSE, warning=FALSE}

file1 <- here::here("model/iLand_simulations/output/Output_plot1.sqlite")
file2 <- here::here("model/iLand_simulations/output/Output_plot1_4deg_20percdrier.sqlite")

# Give some name for the three simulations.
name1 <- "reference"
name2 <- "4deg_20percdrier"

# Read in data using the RSQLite package 
#sqlite.driver  <- DBI::dbDriver("SQLite") #ODY CHANGED! did not work for me
sqlite.driver  <- RSQLite::SQLite()
db1  <- DBI::dbConnect(sqlite.driver, dbname = file1) # connect to the file1

tables.in.the.file <- DBI::dbListTables(db1) # explore the tables in the file1
print(tables.in.the.file)

# We will work with "tree" table and tree-scale data:
tree1 <- DBI::dbReadTable(db1, "tree")
DBI::dbDisconnect(db1)  # disconnect to the file1

# READ IN DATA FROM THE SECOND FILE: -----
db2  <- DBI::dbConnect(sqlite.driver, dbname = file2) # connect to the file2
tree2 <- DBI::dbReadTable(db2, "tree")
DBI::dbDisconnect(db2)

```

Merge the data from the two files together and make a column which tells which comes from which simulation, and study the table. The column "run" will support the plotting where we can use facets in ggplot.

```{r ex12, eval=TRUE, message = FALSE, warning=FALSE}

tree <- rbind(tree1 |> dplyr::mutate(run = name1) , 
              tree2 |> dplyr::mutate(run = name2))

head(tree)
```

To explore a bit the simulation, plot the tree locations at the beginning and the end of the simulation! For plotting we use the colors for the species, and the size of a circles to show dbh differences. Here we divided dbh with the value 20 just for visualization, not to have too huge circles shading each others completely, but still see the trees.

```{r ex13, eval=TRUE, message = FALSE, warning=FALSE}
tree0 <- tree |> dplyr::filter(year == 0)
g1 <- ggplot2::ggplot(tree0, ggplot2::aes(x = x, y = y, color = species)) +
 ggplot2::geom_point(size = tree0$dbh / 20, alpha = 0.7) +
 ggplot2::ggtitle("Year 0") +
 ggplot2::facet_wrap(~run) + ggplot2::theme_bw()


tree100 <- tree |> dplyr::filter(year == 100)
g2 <- ggplot2::ggplot(tree100, ggplot2::aes(x = x, y = y, color = species)) +
 ggplot2::geom_point(size = tree100$dbh / 20, alpha = 0.7) + 
 ggplot2::ggtitle("Year 100") +
 ggplot2::facet_wrap( ~run) + ggplot2::theme_bw()

gridExtra::grid.arrange(g1, g2, ncol = 1)
```

We can see that the species composition is somewhat changed and the forest become more dense. We can even identify the same trees at the same location.

Visualize some changes in time, for example the mean diameter of the trees!

```{r ex14, eval=TRUE, message = FALSE, warning=FALSE}
sum.table <- tree |> dplyr::group_by(year, run) |>
 dplyr::summarise(N = dplyr::n(),
 MD = mean(dbh, na.rm = TRUE), #mean diameter
 BA = sum(basalArea)) #basal area

ggplot2::ggplot(sum.table, ggplot2::aes(x = year, y = MD, color = run)) +
 ggplot2::geom_line(lwd = 2) +
 ggplot2::ylab("Mean diameter [cm]") + ggplot2::theme_bw()
```

We can see that there is an initial increase in mean dbh, then a drop after 20/25 years. This is due to the growing regeneration layer that is produced by the seeds of the existing trees. In the initial year we do not have regeneration layer in the simulations (it is possible to put there, but we do not have it now). And until the small trees grow up to higher than 4 m they are not appearing in the individual *tree* output as they are handled in cohorts.

To study biodiversity aspects, we can calculate biodiversity indicators (Gini, Shannon and other spatial tree diversity indices). Let's use the *adiv* package: https://cran.r-project.org/web/packages/adiv/index.html First we need to change the database structure to have the number of trees for each species in different columns (pivot_wider) without any additional columns for the *adiv* package *speciesdiv* function. We work first only with tree data from one simulation (tree1).

```{r ex15, eval=TRUE, message = FALSE, warning=FALSE}

# First we need to change the 
tlong1 <- tree1 |>
 dplyr::group_by(year, species) |> dplyr::summarise(N = dplyr::n()) |>
 tidyr::pivot_wider(id_cols = 'year', names_from ='species',
                    values_from = 'N', values_fill = 0) |>
 dplyr::ungroup() |>
 dplyr::select(-year) 

 head(tlong1)
```

Then we apply the "speciesdiv" function and we add back the year and run columns to have the information.

```{r ex16, eval=TRUE, message = FALSE, warning=FALSE}

div1 <- data.frame(speciesdiv(tlong1)) |> mutate(year = unique(tree1$year),
 run = name1) 
head(div1)
```

We make the same steps for the other simulation results (tree2).

```{r ex17, eval=TRUE, message = FALSE, warning=FALSE}
tlong2 <- tree2 |>
 group_by(year, species) |> summarise(N=n()) |>
 pivot_wider(id_cols='year', names_from='species',values_from='N', values_fill = 0) |>
 ungroup() |>
 dplyr::select(-year) 

div2<-data.frame(speciesdiv(tlong2)) |> mutate(year=unique(tree2$year),
 run=name2) 

```

We merge them all together and make a plot.

```{r ex18, eval=FALSE, message = FALSE, warning=FALSE}

tlong2<-tree2 |>
 group_by(year, species) |> summarise(N=n()) |>
 pivot_wider(id_cols='year', names_from='species',values_from='N', values_fill = 0) |>
 ungroup() |>
 dplyr::select(-year) 

div2<-data.frame(speciesdiv(tlong2)) |> mutate(year=unique(tree2$year),
 run=name2) 
div<-rbind(div1,div2)

g1<-ggplot(div, aes(year, Shannon , color=run))+
 geom_line(lwd=1.5) +
 labs(x = "Year",y="Shannon index")+theme_bw()

g2<-ggplot(div, aes(year, GiniSimpson , color=run))+
 geom_line(lwd=1.5) +
 labs(x = "Year",y="Gini-Simpson index")+theme_bw()
grid.arrange(g1,g2)
```

We can calculate some additional biodiversity indices using the *treespat* package developed by Francesco Chianucci (fchianucci\@gmail.com).

You can install it using devtools:

```{r ex19, eval=FALSE, message = FALSE, warning=FALSE}
devtools::install_gitlab('fchianucci/treespat')
```

Then, we are ready to use it! We can calculate:

-   Diameter dominance: ADD HERE
-   Diameter differentiation: ADD HERE
-   Stand Complexity Index (SCI): ADD HERE
-   Mingling: ADD HERE

Calculate the indices based on the reference run, then based on the scenario. For each index we add extra columns with the index name, and run name for further analyses.

```{r ex20, eval=FALSE, message = FALSE, warning=FALSE}
library(treespat)

# diameter dominance
# diameter differentiation:
# Stand Complexity Index (SCI):
# mingling
 
ddom<-data.frame(DDOM(tree1, .x = x, .y = y,.mark = dbh, xmax = 100, ymax = 100, 
 max.k = 4, shape='square', .groups=c('year')) |> 
 mutate(index="DDOM", name="Diameter dominance", run=name1))
head(ddom)

diff<-data.frame(DIFF(tree1, .x = x, .y = y,.mark = dbh, xmax = 100, ymax = 100,
 max.k = 4, shape='square', .groups=c('year')) |> 
 mutate(index="DIFF", name="Diameter differentiation", run=name1))
head(diff)

sci<-data.frame(SCI(tree1, .x = x, .y = y, .mark = dbh, .groups=c('year')) |> 
 mutate(index="SCI", name="Stand Complexity Index", run=name1) )
head(sci)

#ming<-MING(tree1, .x = x, .y = y, .species = species, xmax = 100, ymax = 100,
# max.k = 4, shape='square', .groups=c('year')) |> 
# mutate(index="MING", name="Mingling", run=name1)

indices1<-rbind(ddom |> rename(value=DBH.DOM),
 diff |> rename(value=DIFF),
 sci[,-c(3,4)] |> rename(value=mean_SCI) )#this has more columns we need the first two
```

We calculated each index as separate variable and then merged them into indices1. Here I renamed the column names to have it all "value", for easier plotting later on. (each line has the information on which run and which index is the value) We do the same for the scenario simulation, we merge them together and make the plotting.

```{r ex21, eval=FALSE, message = FALSE, warning=FALSE}
ddom<-data.frame(DDOM(tree2, .x = x, .y = y,.mark = dbh, xmax = 100, ymax = 100, 
 max.k = 4, shape='square', .groups=c('year')) |> 
 mutate(index="DDOM", name="Diameter dominance", run=name2))


diff<-data.frame(DIFF(tree2, .x = x, .y = y,.mark = dbh, xmax = 100, ymax = 100,
 max.k = 4, shape='square', .groups=c('year')) |> 
 mutate(index="DIFF", name="Diameter differentiation", run=name2))

sci<-data.frame(SCI(tree2, .x = x, .y = y, .mark = dbh, .groups=c('year')) |> 
 mutate(index="SCI", name="Stand Complexity Index", run=name2))


#ming<-MING(tree2, .x = x, .y = y, .species = species, xmax = 100, ymax = 100,
# max.k = 4, shape='square', .groups=c('year')) |> 
# mutate(index="MING", name="Mingling", run=name2)

indices2<-rbind(ddom |> rename(value=DBH.DOM),
 diff |> rename(value=DIFF),
 sci[,-c(3,4)] |> rename(value=mean_SCI) )

indices<-rbind(indices1,indices2)

ggplot(indices, aes(x=year, y=value, color=run))+
 geom_line(lwd=1)+
 facet_wrap(~name, ncol=2, scales="free")+
 theme_bw() 
```

*ADD interpretation*

###Question B - Group 1 {#sec-B_1}

-   How the species distribution and total living biomass C content changing in time on Plot 1? Compare 0 year and 100 year status in the reference case and in the case of your scenario(s)!

Run the model as it is described in the previous chapters to have at least 2 simulations completed: one with reference conditions and one scenarios with some changes in the environment. Check if you have the output files in the output folder: *iLand_simulations/output/*. If you manage to simualate 2 scenarios, you can expand the code to have file3, and 3rd from each variable, or make the comparison in 2 step always comparing one scenario to the reference conditions at the time. Open the *summerSchoolExerciseProcessBased.Rproj* project in R studio and start working there.

Read in the *landscape* output table from two outputs you have for your plot:

```{r ex22, eval=FALSE, message = FALSE, warning=FALSE}

file1<-"../iLand_simulations/output/Output_plot1.sqlite"
file2<-"../iLand_simulations/output/Output_plot1_4deg_20percdrier.sqlite"

# Give some name for the three simulations.
name1<-"reference"
name2<-"4deg_20percdrier"

# Read in data using the RSQLite package 
sqlite.driver <- dbDriver("SQLite")

# We will work with "landscape" table and tree-scale data:
db1 <- dbConnect(sqlite.driver, dbname = file1) # connect to the file1
landscape1<- dbReadTable(db1,"landscape")
dbDisconnect(db1) # disconnect to the file1

db2 <- dbConnect(sqlite.driver, dbname = file2) # connect to the file2
landscape2<- dbReadTable(db2,"landscape")
dbDisconnect(db2)

```

Merge the data from the three files together and make a column which tells which comes from which simulation, and study the table. The column "run" will support the plotting where we can use facets in ggplot.

```{r ex23, eval=FALSE, message = FALSE, warning=FALSE}

landscape<-rbind(landscape1 |> mutate(run=name1) , 
 landscape2 |> mutate(run=name2))

head(landscape)
```

We can see that the output is given for each year and each species in our 1ha area. Plot the living carbon (total_carbon_kg) in time, coloring by species. We give a unified species coloring in the begining. Plot number of trees and mean diameter. Carbon and number of trees can be plotted in an additive way, but for mean dbh we do line plot per species.

```{r ex24, eval=FALSE, message = FALSE, warning=FALSE}

cols.all=c( "rops"="#e0e0e0","acpl"="#A9A9A9","alin"="#696969","alvi"="#2e2e2e",
 "bepe"="#fadfad","casa"="#7eeadf","coav"="#20c6b6","tipl"="#645394", 
 "ulgl"="#311432","saca"="#D8BFD8","soar"="#DDA0DD","soau"="#BA55D3",
 "pice"="#D27D2D","pini"="#a81c07","algl"="#2ECBE9","tico"="#128FC8", 
 "potr"="#00468B","poni"="#5BAEB7","frex"="#fe9cb5","cabe"="#fe6181",
 "acps"="#fe223e","lade"="#FFFE71","abal"="#FFD800", "pisy"="#A4DE02",
 "fasy"="#76BA1B","piab"="#006600","quro"="#FF7F00", "qupe"="#FF9900", 
 "qupu"="#CC9900")

# We set here the order of the run categories for the table, to have the first
#run first and then the second. (left-right of the plots)
landscape$run<-factor( landscape$run, levels=c(name1,name2))

# Plot the living carbon content, to have tonnes/ha, we divide total_carbon_kg by 1000.
g1<-ggplot(landscape, aes(year, total_carbon_kg/1000 , fill=factor(species)))+
 geom_area() +
 scale_fill_manual(values=cols.all, guide=guide_legend(reverse=TRUE))+
 facet_wrap(~run, nrow=1)+
 labs(x = "Year",y="Living C t/ha",fill = "Species")+
 theme_bw()

g2<-ggplot(landscape, aes(year, count_ha , fill=factor(species)))+
 geom_area() +
 scale_fill_manual(values=cols.all, guide=guide_legend(reverse=TRUE))+
 facet_wrap(~run, nrow=1)+
 labs(x = "Year",y="Number of trees per ha",fill = "Species")+
 theme_bw()

grid.arrange(g1,g2, ncol=1)

g3<-ggplot(landscape, aes(year, dbh_avg_cm , color=factor(species)))+
 geom_line(lwd=1) +
 scale_color_manual(values=cols.all, guide=guide_legend(reverse=TRUE))+
 facet_wrap(~run, nrow=1)+
 labs(x = "Year",y="Mean dbh",fill = "Species")+
 theme_bw()
print(g3)
```

We can see that the forest is growing, it accumulates more and more carbon. We do not have management intervention. Number of trees are increasing as the regeneration layer develops to adult trees (higher than 4m). The species-specific graphs for avg dbh indicates that some species do not have successful regeneration under the scenario. Beech start to dominate and other species do not have the drop in the avg dbh due to regeneration. Calculate the stored C amount in the initial year (year==0) and the last year (year==100)!

```{r ex25, eval=FALSE, message = FALSE, warning=FALSE}
livingC0<-data.frame(landscape |> filter(year==0) |> group_by(run) |> 
 summarize(sum.livingC=sum(total_carbon_kg/1000)) )
print(livingC0)

livingC100<-data.frame(landscape |> filter(year==100) |> group_by(run) |> 
 summarize(sum.livingC=sum(total_carbon_kg/1000)) )
print(livingC100)
```

The initial conditions are same for the runs, but they are ending up at different C levels.

Calculate the stored C amount PER SPECIES in the initial year (year==0) and the last year (year==100)

```{r ex26, eval=FALSE, message = FALSE, warning=FALSE}
species.livingC0<-data.frame(landscape |> filter(year==0) |> group_by(run, species) |> 
 summarize(livingC=sum(total_carbon_kg/1000)) )
print(species.livingC0)

species.livingC100<-data.frame(landscape |> filter(year==100) |> group_by(run, species) |> 
 summarize(livingC=sum(total_carbon_kg/1000)) )
print(species.livingC100)
```

Calculate the species proportions based on the stored C amount in the initial year (year==0) and the last year (year==100) For this we need the total C amount and the species-specific C amount.

```{r ex27, eval=FALSE, message = FALSE, warning=FALSE}
LC0<-left_join(species.livingC0, livingC0, by="run" )
LC0<-data.frame(LC0 |> mutate(spec.prop=livingC/sum.livingC, year=0))
print(LC0)

LC100<-left_join(species.livingC100, livingC100, by="run" )
LC100<-data.frame(LC100 |> mutate(spec.prop=livingC/sum.livingC, year=100))
print(LC100)

```

Put the two tables together and visualize the results!

```{r ex28, eval=FALSE, message = FALSE, warning=FALSE}
LC<-rbind(LC0,LC100)

LC$run<-factor( LC$run, levels=c(name1,name2))

ggplot(LC, aes(fill=species, y=livingC , x=factor(year))) + 
 geom_bar(position="stack", stat="identity")+
 scale_fill_manual(values=cols.all)+
 facet_wrap(~run)+
 ylab("Living C absolute values")+
 theme_bw()




ggplot(LC, aes(fill=species, y=spec.prop, x=factor(year))) + 
 geom_bar(position="stack", stat="identity")+
 scale_fill_manual(values=cols.all)+
 facet_wrap(~run)+
 ylab("Species proportion")+
 theme_bw()

```

### Question A - Group 2 {#sec-A_2}

-   How biodiversity indices are changing in time and across the simulated scenario(s) on Plot 2?

Run the model as it is described in the previous chapters to have at least 2 simulations completed: one with reference conditions and one scenarios with some changes in the environment. Check if you have the output files in the output folder: *iLand_simulations/output/*. If you manage to simualate 2 scenarios, you can expand the code to have file3, and 3rd from each variable, or make the comparison in 2 step always comparing one scenario to the reference conditions at the time.

Open the *summerSchoolExerciseProcessBased.Rproj* project in R studio and start working there.

Read in the *tree* output table from two outputs you have for your plot:

```{r ex29, eval=FALSE, message = FALSE, warning=FALSE}

file1<-"../iLand_simulations/output/Output_plot2.sqlite"
file2<-"../iLand_simulations/output/Output_plot2_4deg_20percdrier.sqlite"

# Give some name for the three simulations.
name1<-"reference"
name2<-"4deg_20percdrier"

# Read in data using the RSQLite package 
sqlite.driver <- dbDriver("SQLite")

db1 <- dbConnect(sqlite.driver, dbname = file1) # connect to the file1

tables.in.the.file<-dbListTables(db1) # explore the tables in the file1
print(tables.in.the.file)

# We will work with "tree" table and tree-scale data:
tree1<- dbReadTable(db1,"tree")
dbDisconnect(db1) # disconnect to the file1

# READ IN DATA FROM THE SECOND FILE: -----
db2 <- dbConnect(sqlite.driver, dbname = file2) # connect to the file2
tree2<- dbReadTable(db2,"tree")
dbDisconnect(db2)

```

Merge the data from the two files together and make a column which tells which comes from which simulation, and study the table. The column "run" will support the plotting where we can use facets in ggplot.

```{r ex30, eval=FALSE, message = FALSE, warning=FALSE}

tree<-rbind(tree1 |> mutate(run=name1) , 
 tree2 |> mutate(run=name2))

head(tree)
```

To explore a bit the simulation, plot the tree locations at the beginning and the end of the simulation! For plotting we use the colors for the species, and the size of a circles to show dbh differences. Here we divided dbh with the value 20 just for visualization, not to have too huge circles shading each others completely, but still see the trees.

```{r ex31, eval=FALSE, message = FALSE, warning=FALSE}
tree0<-tree |> filter(year==0)
g1<-ggplot(tree0, aes(x=x, y=y, color=species))+
 geom_point(size=tree0$dbh/20, alpha=0.7)+
 ggtitle("Year 0")+
 facet_wrap(~run)+theme_bw()


tree100<-tree |> filter(year==100)
g2<-ggplot(tree100, aes(x=x, y=y, color=species))+
 geom_point(size=tree100$dbh/20, alpha=0.7)+ 
 ggtitle("Year 100")+
 facet_wrap(~run)+theme_bw()

grid.arrange(g1,g2, ncol=1)
```

We can see that the species composition is somewhat changed and the forest become more dense. We can even identify the same trees at the same location.

Visualize some changes in time, for example the mean diameter of the trees!

```{r ex32, eval=FALSE, message = FALSE, warning=FALSE}
sum.table<- tree |> group_by(year, run) |>
 summarise(N=n(),
 MD=mean(dbh,na.rm=TRUE), #mean diameter
 BA=sum(basalArea)) #basal area

ggplot(sum.table, aes(x=year, y=MD, color=run)) +
 geom_line(lwd=2)+
 ylab("Mean diameter [cm]")+theme_bw()
```

We can see that there is an initial increase in mean dbh, then a drop after 20/25 years. This is due to the growing regeneration layer that is produced by the seeds of the existing trees. In the initial year we do not have regeneration layer in the simulations (it is possible to put there, but we do not have it now). And until the small trees grow up to higher than 4 m they are not appearing in the individual *tree* output as they are handled in cohorts.

To study biodiversity aspects, we can calculate biodiversity indicators (Gini, Shannon and other spatial tree diversity indices). Let's use the *adiv* package: https://cran.r-project.org/web/packages/adiv/index.html First we need to change the database structure to have the number of trees for each species in different columns (pivot_wider) without any additional columns for the *adiv* package *speciesdiv* function. We work first only with tree data from one simulation (tree1).

```{r ex33, eval=FALSE, message = FALSE, warning=FALSE}

library(adiv)

# First we need to change the 
tlong1<-tree1 |>
 group_by(year, species) |> summarise(N=n()) |>
 pivot_wider(id_cols='year', names_from='species',values_from='N', values_fill = 0) |>
 ungroup() |>
 dplyr::select(-year) 
head(tlong1)
```

Then we apply the "speciesdiv" function and we add back the year and run columns to have the information.

```{r ex34, eval=FALSE, message = FALSE, warning=FALSE}

div1<-data.frame(speciesdiv(tlong1)) |> mutate(year=unique(tree1$year),
 run=name1) 
head(div1)
```

We make the same steps for the other simulation results (tree2).

```{r ex35, eval=FALSE, message = FALSE, warning=FALSE}
tlong2<-tree2 |>
 group_by(year, species) |> summarise(N=n()) |>
 pivot_wider(id_cols='year', names_from='species',values_from='N', values_fill = 0) |>
 ungroup() |>
 dplyr::select(-year) 

div2<-data.frame(speciesdiv(tlong2)) |> mutate(year=unique(tree2$year),
 run=name2) 

```

We merge them all together and make a plot.

```{r ex36, eval=FALSE, message = FALSE, warning=FALSE}

tlong2<-tree2 |>
 group_by(year, species) |> summarise(N=n()) |>
 pivot_wider(id_cols='year', names_from='species',values_from='N', values_fill = 0) |>
 ungroup() |>
 dplyr::select(-year) 

div2<-data.frame(speciesdiv(tlong2)) |> mutate(year=unique(tree2$year),
 run=name2) 
div<-rbind(div1,div2)

g1<-ggplot(div, aes(year, Shannon , color=run))+
 geom_line(lwd=1.5) +
 labs(x = "Year",y="Shannon index")+ theme_bw()

g2<-ggplot(div, aes(year, GiniSimpson , color=run))+
 geom_line(lwd=1.5) +
 labs(x = "Year",y="Gini-Simpson index")+theme_bw()
grid.arrange(g1,g2)
```

We can calculate some additional biodiversity indices using the *treespat* package developed by Francesco Chianucci (fchianucci\@gmail.com).

You can install it using devtools:

```{r ex37, eval=FALSE, message = FALSE, warning=FALSE}
devtools::install_gitlab('fchianucci/treespat')
```

Then, we are ready to use it! We can calculate:

-   Diameter dominance: ADD HERE
-   Diameter differentiation: ADD HERE
-   Stand Complexity Index (SCI): ADD HERE
-   Mingling: ADD HERE

Calculate the indices based on the reference run, then based on the scenario. For each index we add extra columns with the index name, and run name for further analyses.

```{r ex38, eval=FALSE, message = FALSE, warning=FALSE}
library(treespat)

# diameter dominance
# diameter differentiation:
# Stand Complexity Index (SCI):
# mingling
 
ddom<-data.frame(DDOM(tree1, .x = x, .y = y,.mark = dbh, xmax = 100, ymax = 100, 
 max.k = 4, shape='square', .groups=c('year')) |> 
 mutate(index="DDOM", name="Diameter dominance", run=name1))
head(ddom)

diff<-data.frame(DIFF(tree1, .x = x, .y = y,.mark = dbh, xmax = 100, ymax = 100,
 max.k = 4, shape='square', .groups=c('year')) |> 
 mutate(index="DIFF", name="Diameter differentiation", run=name1))
head(diff)

sci<-data.frame(SCI(tree1, .x = x, .y = y, .mark = dbh, .groups=c('year')) |> 
 mutate(index="SCI", name="Stand Complexity Index", run=name1) )
head(sci)

#ming<-MING(tree1, .x = x, .y = y, .species = species, xmax = 100, ymax = 100,
# max.k = 4, shape='square', .groups=c('year')) |> 
# mutate(index="MING", name="Mingling", run=name1)

indices1<-rbind(ddom |> rename(value=DBH.DOM),
 diff |> rename(value=DIFF),
 sci[,-c(3,4)] |> rename(value=mean_SCI) )#this has more columns we need the first two
```

We calculated each index as separate variable and then merged them into indices1. Here I renamed the column names to have it all "value", for easier plotting later on. (each line has the information on which run and which index is the value) We do the same for the scenario simulation, we merge them together and make the plotting.

```{r ex39, eval=FALSE, message = FALSE, warning=FALSE}
ddom<-data.frame(DDOM(tree2, .x = x, .y = y,.mark = dbh, xmax = 100, ymax = 100, 
 max.k = 4, shape='square', .groups=c('year')) |> 
 mutate(index="DDOM", name="Diameter dominance", run=name2))


diff<-data.frame(DIFF(tree2, .x = x, .y = y,.mark = dbh, xmax = 100, ymax = 100,
 max.k = 4, shape='square', .groups=c('year')) |> 
 mutate(index="DIFF", name="Diameter differentiation", run=name2))

sci<-data.frame(SCI(tree2, .x = x, .y = y, .mark = dbh, .groups=c('year')) |> 
 mutate(index="SCI", name="Stand Complexity Index", run=name2))


#ming<-MING(tree2, .x = x, .y = y, .species = species, xmax = 100, ymax = 100,
# max.k = 4, shape='square', .groups=c('year')) |> 
# mutate(index="MING", name="Mingling", run=name2)

indices2<-rbind(ddom |> rename(value=DBH.DOM),
 diff |> rename(value=DIFF),
 sci[,-c(3,4)] |> rename(value=mean_SCI) )

indices<-rbind(indices1,indices2)

ggplot(indices, aes(x=year, y=value, color=run))+
 geom_line(lwd=1)+
 facet_wrap(~name, ncol=2, scales="free")+
 theme_bw() 
```

*ADD interpretation*

### Question B - Group 2 {#sec-B_2}

-   How the species distribution and total living biomass C content changing in time on Plot 2? Compare 0 year and 100 year status in the reference case and in the case of your scenario(s)!

Run the model as it is described in the previous chapters to have at least 2 simulations completed: one with reference conditions and one scenarios with some changes in the environment. Check if you have the output files in the output folder: *iLand_simulations/output/*. If you manage to simualate 2 scenarios, you can expand the code to have file3, and 3rd from each variable, or make the comparison in 2 step always comparing one scenario to the reference conditions at the time. Open the *summerSchoolExerciseProcessBased.Rproj* project in R studio and start working there.

Read in the *landscape* output table from two outputs you have for your plot:

```{r ex40, eval=FALSE, message = FALSE, warning=FALSE}

file1<-"../iLand_simulations/output/Output_plot2.sqlite"
file2<-"../iLand_simulations/output/Output_plot2_4deg_20percdrier.sqlite"

# Give some name for the three simulations.
name1<-"reference"
name2<-"4deg_20percdrier"

# Read in data using the RSQLite package 
sqlite.driver <- dbDriver("SQLite")

# We will work with "landscape" table and tree-scale data:
db1 <- dbConnect(sqlite.driver, dbname = file1) # connect to the file1
landscape1<- dbReadTable(db1,"landscape")
dbDisconnect(db1) # disconnect to the file1

db2 <- dbConnect(sqlite.driver, dbname = file2) # connect to the file2
landscape2<- dbReadTable(db2,"landscape")
dbDisconnect(db2)

```

Merge the data from the three files together and make a column which tells which comes from which simulation, and study the table. The column "run" will support the plotting where we can use facets in ggplot.

```{r ex41, eval=FALSE, message = FALSE, warning=FALSE}

landscape<-rbind(landscape1 |> mutate(run=name1) , 
 landscape2 |> mutate(run=name2))

head(landscape)
```

We can see that the output is given for each year and each species in our 1ha area. Plot the living carbon (total_carbon_kg) in time, coloring by species. We give a unified species coloring in the begining. Plot number of trees and mean diameter. Carbon and number of trees can be plotted in an additive way, but for mean dbh we do line plot per species.

```{r ex42, eval=FALSE, message = FALSE, warning=FALSE}

cols.all=c( "rops"="#e0e0e0","acpl"="#A9A9A9","alin"="#696969","alvi"="#2e2e2e",
 "bepe"="#fadfad","casa"="#7eeadf","coav"="#20c6b6","tipl"="#645394", 
 "ulgl"="#311432","saca"="#D8BFD8","soar"="#DDA0DD","soau"="#BA55D3",
 "pice"="#D27D2D","pini"="#a81c07","algl"="#2ECBE9","tico"="#128FC8", 
 "potr"="#00468B","poni"="#5BAEB7","frex"="#fe9cb5","cabe"="#fe6181",
 "acps"="#fe223e","lade"="#FFFE71","abal"="#FFD800", "pisy"="#A4DE02",
 "fasy"="#76BA1B","piab"="#006600","quro"="#FF7F00", "qupe"="#FF9900", 
 "qupu"="#CC9900")

# We set here the order of the run categories for the table, to have the first
#run first and then the second. (left-right of the plots)
landscape$run<-factor( landscape$run, levels=c(name1,name2))

# Plot the living carbon content, to have tonnes/ha, we divide total_carbon_kg by 1000.
g1<-ggplot(landscape, aes(year, total_carbon_kg/1000 , fill=factor(species)))+
 geom_area() +
 scale_fill_manual(values=cols.all, guide=guide_legend(reverse=TRUE))+
 facet_wrap(~run, nrow=1)+
 labs(x = "Year",y="Living C t/ha",fill = "Species")+
 theme_bw()

g2<-ggplot(landscape, aes(year, count_ha , fill=factor(species)))+
 geom_area() +
 scale_fill_manual(values=cols.all, guide=guide_legend(reverse=TRUE))+
 facet_wrap(~run, nrow=1)+
 labs(x = "Year",y="Number of trees per ha",fill = "Species")+
 theme_bw()

grid.arrange(g1,g2, ncol=1)

g3<-ggplot(landscape, aes(year, dbh_avg_cm , color=factor(species)))+
 geom_line(lwd=1) +
 scale_color_manual(values=cols.all, guide=guide_legend(reverse=TRUE))+
 facet_wrap(~run, nrow=1)+
 labs(x = "Year",y="Mean dbh",fill = "Species")+
 theme_bw()
print(g3)
```

We can see that the forest is growing, it accumulates more and more carbon. We do not have management intervention. Number of trees are increasing as the regeneration layer develops to adult trees (higher than 4m). The species-specific graphs for avg dbh indicates that some species do not have successful regeneration under the scenario. Beech start to dominate and other species do not have the drop in the avg dbh due to regeneration. Calculate the stored C amount in the initial year (year==0) and the last year (year==100)!

```{r ex43, eval=FALSE, message = FALSE, warning=FALSE}
livingC0<-data.frame(landscape |> filter(year==0) |> group_by(run) |> 
 summarize(sum.livingC=sum(total_carbon_kg/1000)) )
print(livingC0)

livingC100<-data.frame(landscape |> filter(year==100) |> group_by(run) |> 
 summarize(sum.livingC=sum(total_carbon_kg/1000)) )
print(livingC100)
```

The initial conditions are same for the runs, but they are ending up at different C levels.

Calculate the stored C amount PER SPECIES in the initial year (year==0) and the last year (year==100)

```{r ex44, eval=FALSE, message = FALSE, warning=FALSE}
species.livingC0<-data.frame(landscape |> filter(year==0) |> group_by(run, species) |> 
 summarize(livingC=sum(total_carbon_kg/1000)) )
print(species.livingC0)

species.livingC100<-data.frame(landscape |> filter(year==100) |> group_by(run, species) |> 
 summarize(livingC=sum(total_carbon_kg/1000)) )
print(species.livingC100)
```

Calculate the species proportions based on the stored C amount in the initial year (year==0) and the last year (year==100) For this we need the total C amount and the species-specific C amount.

```{r ex45, eval=FALSE, message = FALSE, warning=FALSE}
LC0<-left_join(species.livingC0, livingC0, by="run" )
LC0<-data.frame(LC0 |> mutate(spec.prop=livingC/sum.livingC, year=0))
print(LC0)

LC100<-left_join(species.livingC100, livingC100, by="run" )
LC100<-data.frame(LC100 |> mutate(spec.prop=livingC/sum.livingC, year=100))
print(LC100)

```

Put the two tables together and visualize the results!

```{r ex46, eval=FALSE, message = FALSE, warning=FALSE}
LC<-rbind(LC0,LC100)

LC$run<-factor( LC$run, levels=c(name1,name2))

ggplot(LC, aes(fill=species, y=livingC , x=factor(year))) + 
 geom_bar(position="stack", stat="identity")+
 scale_fill_manual(values=cols.all)+
 facet_wrap(~run)+
 ylab("Living C absolute values")+
 theme_bw()




ggplot(LC, aes(fill=species, y=spec.prop, x=factor(year))) + 
 geom_bar(position="stack", stat="identity")+
 scale_fill_manual(values=cols.all)+
 facet_wrap(~run)+
 ylab("Species proportion")+
 theme_bw()

```

### Question A - Group 3 {#sec-A_3}

-   How biodiversity indices are changing in time and across the simulated scenario(s) on Plot 3?

Run the model as it is described in the previous chapters to have at least 2 simulations completed: one with reference conditions and one scenarios with some changes in the environment. Check if you have the output files in the output folder: *iLand_simulations/output/*. If you manage to simualate 2 scenarios, you can expand the code to have file3, and 3rd from each variable, or make the comparison in 2 step always comparing one scenario to the reference conditions at the time.

Open the *summerSchoolExerciseProcessBased.Rproj* project in R studio and start working there.

Read in the *tree* output table from two outputs you have for your plot:

```{r ex47, eval=FALSE, message = FALSE, warning=FALSE}

file1<-"../iLand_simulations/output/Output_plot3.sqlite"
file2<-"../iLand_simulations/output/Output_plot3_4deg_20percdrier.sqlite"

# Give some name for the three simulations.
name1<-"reference"
name2<-"4deg_20percdrier"

# Read in data using the RSQLite package 
sqlite.driver <- dbDriver("SQLite")

db1 <- dbConnect(sqlite.driver, dbname = file1) # connect to the file1

tables.in.the.file<-dbListTables(db1) # explore the tables in the file1
print(tables.in.the.file)

# We will work with "tree" table and tree-scale data:
tree1<- dbReadTable(db1,"tree")
dbDisconnect(db1) # disconnect to the file1

# READ IN DATA FROM THE SECOND FILE: -----
db2 <- dbConnect(sqlite.driver, dbname = file2) # connect to the file2
tree2<- dbReadTable(db2,"tree")
dbDisconnect(db2)

```

Merge the data from the two files together and make a column which tells which comes from which simulation, and study the table. The column "run" will support the plotting where we can use facets in ggplot.

```{r ex48, eval=FALSE, message = FALSE, warning=FALSE}

tree<-rbind(tree1 |> mutate(run=name1) , 
 tree2 |> mutate(run=name2))

head(tree)
```

To explore a bit the simulation, plot the tree locations at the beginning and the end of the simulation! For plotting we use the colors for the species, and the size of a circles to show dbh differences. Here we divided dbh with the value 20 just for visualization, not to have too huge circles shading each others completely, but still see the trees.

```{r ex49, eval=FALSE, message = FALSE, warning=FALSE}
tree0<-tree |> filter(year==0)
g1<-ggplot(tree0, aes(x=x, y=y, color=species))+
 geom_point(size=tree0$dbh/20, alpha=0.7)+
 ggtitle("Year 0")+
 facet_wrap(~run)+theme_bw()


tree100<-tree |> filter(year==100)
g2<-ggplot(tree100, aes(x=x, y=y, color=species))+
 geom_point(size=tree100$dbh/20, alpha=0.7)+ 
 ggtitle("Year 100")+
 facet_wrap(~run)+theme_bw()

grid.arrange(g1,g2, ncol=1)
```

We can see that the species composition is somewhat changed and the forest become more dense. We can even identify the same trees at the same location.

Visualize some changes in time, for example the mean diameter of the trees!

```{r ex50, eval=FALSE, message = FALSE, warning=FALSE}
sum.table<- tree |> group_by(year, run) |>
 summarise(N=n(),
 MD=mean(dbh,na.rm=TRUE), #mean diameter
 BA=sum(basalArea)) #basal area

ggplot(sum.table, aes(x=year, y=MD, color=run)) +
 geom_line(lwd=2)+
 ylab("Mean diameter [cm]")+theme_bw()
```

We can see that there is an initial increase in mean dbh, then a drop after 20/25 years. This is due to the growing regeneration layer that is produced by the seeds of the existing trees. In the initial year we do not have regeneration layer in the simulations (it is possible to put there, but we do not have it now). And until the small trees grow up to higher than 4 m they are not appearing in the individual *tree* output as they are handled in cohorts.

To study biodiversity aspects, we can calculate biodiversity indicators (Gini, Shannon and other spatial tree diversity indices). Let's use the *adiv* package: https://cran.r-project.org/web/packages/adiv/index.html First we need to change the database structure to have the number of trees for each species in different columns (pivot_wider) without any additional columns for the *adiv* package *speciesdiv* function. We work first only with tree data from one simulation (tree1).

```{r ex51, eval=FALSE, message = FALSE, warning=FALSE}

library(adiv)

# First we need to change the 
tlong1<-tree1 |>
 group_by(year, species) |> summarise(N=n()) |>
 pivot_wider(id_cols='year', names_from='species',values_from='N', values_fill = 0) |>
 ungroup() |>
 dplyr::select(-year) 
head(tlong1)
```

Then we apply the "speciesdiv" function and we add back the year and run columns to have the information.

```{r ex52, eval=FALSE, message = FALSE, warning=FALSE}

div1<-data.frame(speciesdiv(tlong1)) |> mutate(year=unique(tree1$year),
 run=name1) 
head(div1)
```

We make the same steps for the other simulation results (tree2).

```{r ex53, eval=FALSE, message = FALSE, warning=FALSE}
tlong2<-tree2 |>
 group_by(year, species) |> summarise(N=n()) |>
 pivot_wider(id_cols='year', names_from='species',values_from='N', values_fill = 0) |>
 ungroup() |>
 dplyr::select(-year) 

div2<-data.frame(speciesdiv(tlong2)) |> mutate(year=unique(tree2$year),
 run=name2) 

```

We merge them all together and make a plot.

```{r ex54, eval=FALSE, message = FALSE, warning=FALSE}

tlong2<-tree2 |>
 group_by(year, species) |> summarise(N=n()) |>
 pivot_wider(id_cols='year', names_from='species',values_from='N', values_fill = 0) |>
 ungroup() |>
 dplyr::select(-year) 

div2<-data.frame(speciesdiv(tlong2)) |> mutate(year=unique(tree2$year),
 run=name2) 
div<-rbind(div1,div2)

g1<-ggplot(div, aes(year, Shannon , color=run))+
 geom_line(lwd=1.5) +
 labs(x = "Year",y="Shannon index")+theme_bw()

g2<-ggplot(div, aes(year, GiniSimpson , color=run))+
 geom_line(lwd=1.5) +
 labs(x = "Year",y="Gini-Simpson index")+theme_bw()
grid.arrange(g1,g2)
```

We can calculate some additional biodiversity indices using the *treespat* package developed by Francesco Chianucci (fchianucci\@gmail.com).

You can install it using devtools:

```{r ex55, eval=FALSE, message = FALSE, warning=FALSE}
devtools::install_gitlab('fchianucci/treespat')
```

Then, we are ready to use it! We can calculate: Then, we are ready to use it! We can calculate:

-   Diameter dominance: ADD HERE
-   Diameter differentiation: ADD HERE
-   Stand Complexity Index (SCI): ADD HERE
-   Mingling: ADD HERE

Calculate the indices based on the reference run, then based on the scenario. For each index we add extra columns with the index name, and run name for further analyses.

```{r ex56, eval=FALSE, message = FALSE, warning=FALSE}
library(treespat)

# diameter dominance
# diameter differentiation:
# Stand Complexity Index (SCI):
# mingling
 
ddom<-data.frame(DDOM(tree1, .x = x, .y = y,.mark = dbh, xmax = 100, ymax = 100, 
 max.k = 4, shape='square', .groups=c('year')) |> 
 mutate(index="DDOM", name="Diameter dominance", run=name1))
head(ddom)

diff<-data.frame(DIFF(tree1, .x = x, .y = y,.mark = dbh, xmax = 100, ymax = 100,
 max.k = 4, shape='square', .groups=c('year')) |> 
 mutate(index="DIFF", name="Diameter differentiation", run=name1))
head(diff)

sci<-data.frame(SCI(tree1, .x = x, .y = y, .mark = dbh, .groups=c('year')) |> 
 mutate(index="SCI", name="Stand Complexity Index", run=name1) )
head(sci)

#ming<-MING(tree1, .x = x, .y = y, .species = species, xmax = 100, ymax = 100,
# max.k = 4, shape='square', .groups=c('year')) |> 
# mutate(index="MING", name="Mingling", run=name1)

indices1<-rbind(ddom |> rename(value=DBH.DOM),
 diff |> rename(value=DIFF),
 sci[,-c(3,4)] |> rename(value=mean_SCI) )#this has more columns we need the first two
```

We calculated each index as separate variable and then merged them into indices1. Here I renamed the column names to have it all "value", for easier plotting later on. (each line has the information on which run and which index is the value) We do the same for the scenario simulation, we merge them together and make the plotting.

```{r ex57, eval=FALSE, message = FALSE, warning=FALSE}
ddom<-data.frame(DDOM(tree2, .x = x, .y = y,.mark = dbh, xmax = 100, ymax = 100, 
 max.k = 4, shape='square', .groups=c('year')) |> 
 mutate(index="DDOM", name="Diameter dominance", run=name2))


diff<-data.frame(DIFF(tree2, .x = x, .y = y,.mark = dbh, xmax = 100, ymax = 100,
 max.k = 4, shape='square', .groups=c('year')) |> 
 mutate(index="DIFF", name="Diameter differentiation", run=name2))

sci<-data.frame(SCI(tree2, .x = x, .y = y, .mark = dbh, .groups=c('year')) |> 
 mutate(index="SCI", name="Stand Complexity Index", run=name2))


#ming<-MING(tree2, .x = x, .y = y, .species = species, xmax = 100, ymax = 100,
# max.k = 4, shape='square', .groups=c('year')) |> 
# mutate(index="MING", name="Mingling", run=name2)

indices2<-rbind(ddom |> rename(value=DBH.DOM),
 diff |> rename(value=DIFF),
 sci[,-c(3,4)] |> rename(value=mean_SCI) )

indices<-rbind(indices1,indices2)

ggplot(indices, aes(x=year, y=value, color=run))+
 geom_line(lwd=1)+
 facet_wrap(~name, ncol=2, scales="free")+
 theme_bw() 
```

*ADD interpretation*

### Question B - Group 3 {#sec-B_3}

-   How the species distribution and total living biomass C content changing in time on Plot 3? Compare 0 year and 100 year status in the reference case and in the case of your scenario(s)!

Run the model as it is described in the previous chapters to have at least 2 simulations completed: one with reference conditions and one scenarios with some changes in the environment. Check if you have the output files in the output folder: *iLand_simulations/output/*. If you manage to simualate 2 scenarios, you can expand the code to have file3, and 3rd from each variable, or make the comparison in 2 step always comparing one scenario to the reference conditions at the time. Open the *summerSchoolExerciseProcessBased.Rproj* project in R studio and start working there.

Read in the *landscape* output table from two outputs you have for your plot:

```{r ex58, eval=FALSE, message = FALSE, warning=FALSE}

file1<-"../iLand_simulations/output/Output_plot3.sqlite"
file2<-"../iLand_simulations/output/Output_plot3_4deg_20percdrier.sqlite"

# Give some name for the three simulations.
name1<-"reference"
name2<-"4deg_20percdrier"

# Read in data using the RSQLite package 
sqlite.driver <- dbDriver("SQLite")

# We will work with "landscape" table and tree-scale data:
db1 <- dbConnect(sqlite.driver, dbname = file1) # connect to the file1
landscape1<- dbReadTable(db1,"landscape")
dbDisconnect(db1) # disconnect to the file1

db2 <- dbConnect(sqlite.driver, dbname = file2) # connect to the file2
landscape2<- dbReadTable(db2,"landscape")
dbDisconnect(db2)

```

Merge the data from the three files together and make a column which tells which comes from which simulation, and study the table. The column "run" will support the plotting where we can use facets in ggplot.

```{r ex59, eval=FALSE, message = FALSE, warning=FALSE}

landscape<-rbind(landscape1 |> mutate(run=name1) , 
 landscape2 |> mutate(run=name2))

head(landscape)
```

We can see that the output is given for each year and each species in our 1ha area. Plot the living carbon (total_carbon_kg) in time, coloring by species. We give a unified species coloring in the begining. Plot number of trees and mean diameter. Carbon and number of trees can be plotted in an additive way, but for mean dbh we do line plot per species.

```{r ex60, eval=FALSE, message = FALSE, warning=FALSE}

cols.all=c( "rops"="#e0e0e0","acpl"="#A9A9A9","alin"="#696969","alvi"="#2e2e2e",
 "bepe"="#fadfad","casa"="#7eeadf","coav"="#20c6b6","tipl"="#645394", 
 "ulgl"="#311432","saca"="#D8BFD8","soar"="#DDA0DD","soau"="#BA55D3",
 "pice"="#D27D2D","pini"="#a81c07","algl"="#2ECBE9","tico"="#128FC8", 
 "potr"="#00468B","poni"="#5BAEB7","frex"="#fe9cb5","cabe"="#fe6181",
 "acps"="#fe223e","lade"="#FFFE71","abal"="#FFD800", "pisy"="#A4DE02",
 "fasy"="#76BA1B","piab"="#006600","quro"="#FF7F00", "qupe"="#FF9900", 
 "qupu"="#CC9900")

# We set here the order of the run categories for the table, to have the first
#run first and then the second. (left-right of the plots)
landscape$run<-factor( landscape$run, levels=c(name1,name2))

# Plot the living carbon content, to have tonnes/ha, we divide total_carbon_kg by 1000.
g1<-ggplot(landscape, aes(year, total_carbon_kg/1000 , fill=factor(species)))+
 geom_area() +
 scale_fill_manual(values=cols.all, guide=guide_legend(reverse=TRUE))+
 facet_wrap(~run, nrow=1)+
 labs(x = "Year",y="Living C t/ha",fill = "Species")+
 theme_bw()

g2<-ggplot(landscape, aes(year, count_ha , fill=factor(species)))+
 geom_area() +
 scale_fill_manual(values=cols.all, guide=guide_legend(reverse=TRUE))+
 facet_wrap(~run, nrow=1)+
 labs(x = "Year",y="Number of trees per ha",fill = "Species")+
 theme_bw()

grid.arrange(g1,g2, ncol=1)

g3<-ggplot(landscape, aes(year, dbh_avg_cm , color=factor(species)))+
 geom_line(lwd=1) +
 scale_color_manual(values=cols.all, guide=guide_legend(reverse=TRUE))+
 facet_wrap(~run, nrow=1)+
 labs(x = "Year",y="Mean dbh",fill = "Species")+
 theme_bw()
print(g3)
```

We can see that the forest is growing, it accumulates more and more carbon. We do not have management intervention. Number of trees are increasing as the regeneration layer develops to adult trees (higher than 4m). The species-specific graphs for avg dbh indicates that some species do not have successful regeneration under the scenario. Beech start to dominate and other species do not have the drop in the avg dbh due to regeneration. Calculate the stored C amount in the initial year (year==0) and the last year (year==100)!

```{r ex61, eval=FALSE, message = FALSE, warning=FALSE}
livingC0<-data.frame(landscape |> filter(year==0) |> group_by(run) |> 
 summarize(sum.livingC=sum(total_carbon_kg/1000)) )
print(livingC0)

livingC100<-data.frame(landscape |> filter(year==100) |> group_by(run) |> 
 summarize(sum.livingC=sum(total_carbon_kg/1000)) )
print(livingC100)
```

The initial conditions are same for the runs, but they are ending up at different C levels.

Calculate the stored C amount PER SPECIES in the initial year (year==0) and the last year (year==100)

```{r ex62, eval=FALSE, message = FALSE, warning=FALSE}
species.livingC0<-data.frame(landscape |> filter(year==0) |> group_by(run, species) |> 
 summarize(livingC=sum(total_carbon_kg/1000)) )
print(species.livingC0)

species.livingC100<-data.frame(landscape |> filter(year==100) |> group_by(run, species) |> 
 summarize(livingC=sum(total_carbon_kg/1000)) )
print(species.livingC100)
```

Calculate the species proportions based on the stored C amount in the initial year (year==0) and the last year (year==100) For this we need the total C amount and the species-specific C amount.

```{r ex63, eval=FALSE, message = FALSE, warning=FALSE}
LC0<-left_join(species.livingC0, livingC0, by="run" )
LC0<-data.frame(LC0 |> mutate(spec.prop=livingC/sum.livingC, year=0))
print(LC0)

LC100<-left_join(species.livingC100, livingC100, by="run" )
LC100<-data.frame(LC100 |> mutate(spec.prop=livingC/sum.livingC, year=100))
print(LC100)

```

Put the two tables together and visualize the results!

```{r ex64, eval=FALSE, message = FALSE, warning=FALSE}
LC<-rbind(LC0,LC100)

LC$run<-factor( LC$run, levels=c(name1,name2))

ggplot(LC, aes(fill=species, y=livingC , x=factor(year))) + 
 geom_bar(position="stack", stat="identity")+
 scale_fill_manual(values=cols.all)+
 facet_wrap(~run)+
 ylab("Living C absolute values")+
 theme_bw()




ggplot(LC, aes(fill=species, y=spec.prop, x=factor(year))) + 
 geom_bar(position="stack", stat="identity")+
 scale_fill_manual(values=cols.all)+
 facet_wrap(~run)+
 ylab("Species proportion")+
 theme_bw()

```

### Question A - Group 4 {#sec-A_4}

-   How biodiversity indices are changing in time and across the simulated scenario(s) on Plot 4?

Run the model as it is described in the previous chapters to have at least 2 simulations completed: one with reference conditions and one scenarios with some changes in the environment. Check if you have the output files in the output folder: *iLand_simulations/output/*. If you manage to simualate 2 scenarios, you can expand the code to have file3, and 3rd from each variable, or make the comparison in 2 step always comparing one scenario to the reference conditions at the time.

Open the *summerSchoolExerciseProcessBased.Rproj* project in R studio and start working there.

Read in the *tree* output table from two outputs you have for your plot:

```{r ex65, eval=FALSE, message = FALSE, warning=FALSE}

file1<-"../iLand_simulations/output/Output_plot4.sqlite"
file2<-"../iLand_simulations/output/Output_plot4_4deg_20percdrier.sqlite"

# Give some name for the three simulations.
name1<-"reference"
name2<-"4deg_20percdrier"

# Read in data using the RSQLite package 
sqlite.driver <- dbDriver("SQLite")

db1 <- dbConnect(sqlite.driver, dbname = file1) # connect to the file1

tables.in.the.file<-dbListTables(db1) # explore the tables in the file1
print(tables.in.the.file)

# We will work with "tree" table and tree-scale data:
tree1<- dbReadTable(db1,"tree")
dbDisconnect(db1) # disconnect to the file1

# READ IN DATA FROM THE SECOND FILE: -----
db2 <- dbConnect(sqlite.driver, dbname = file2) # connect to the file2
tree2<- dbReadTable(db2,"tree")
dbDisconnect(db2)

```

Merge the data from the two files together and make a column which tells which comes from which simulation, and study the table. The column "run" will support the plotting where we can use facets in ggplot.

```{r ex66, eval=FALSE, message = FALSE, warning=FALSE}

tree<-rbind(tree1 |> mutate(run=name1) , 
 tree2 |> mutate(run=name2))

head(tree)
```

To explore a bit the simulation, plot the tree locations at the beginning and the end of the simulation! For plotting we use the colors for the species, and the size of a circles to show dbh differences. Here we divided dbh with the value 20 just for visualization, not to have too huge circles shading each others completely, but still see the trees.

```{r ex67, eval=FALSE, message = FALSE, warning=FALSE}
tree0<-tree |> filter(year==0)
g1<-ggplot(tree0, aes(x=x, y=y, color=species))+
 geom_point(size=tree0$dbh/20, alpha=0.7)+
 ggtitle("Year 0")+
 facet_wrap(~run)+theme_bw()


tree100<-tree |> filter(year==100)
g2<-ggplot(tree100, aes(x=x, y=y, color=species))+
 geom_point(size=tree100$dbh/20, alpha=0.7)+ 
 ggtitle("Year 100")+
 facet_wrap(~run)+theme_bw()

grid.arrange(g1,g2, ncol=1)
```

We can see that the species composition is somewhat changed and the forest become more dense. We can even identify the same trees at the same location.

Visualize some changes in time, for example the mean diameter of the trees!

```{r ex68, eval=FALSE, message = FALSE, warning=FALSE}
sum.table<- tree |> group_by(year, run) |>
 summarise(N=n(),
 MD=mean(dbh,na.rm=TRUE), #mean diameter
 BA=sum(basalArea)) #basal area

ggplot(sum.table, aes(x=year, y=MD, color=run)) +
 geom_line(lwd=2)+
 ylab("Mean diameter [cm]")+theme_bw()
```

We can see that there is an initial increase in mean dbh, then a drop after 20/25 years. This is due to the growing regeneration layer that is produced by the seeds of the existing trees. In the initial year we do not have regeneration layer in the simulations (it is possible to put there, but we do not have it now). And until the small trees grow up to higher than 4 m they are not appearing in the individual *tree* output as they are handled in cohorts.

To study biodiversity aspects, we can calculate biodiversity indicators (Gini, Shannon and other spatial tree diversity indices). Let's use the *adiv* package: https://cran.r-project.org/web/packages/adiv/index.html First we need to change the database structure to have the number of trees for each species in different columns (pivot_wider) without any additional columns for the *adiv* package *speciesdiv* function. We work first only with tree data from one simulation (tree1).

```{r ex69, eval=FALSE, message = FALSE, warning=FALSE}

library(adiv)

# First we need to change the 
tlong1<-tree1 |>
 group_by(year, species) |> summarise(N=n()) |>
 pivot_wider(id_cols='year', names_from='species',values_from='N', values_fill = 0) |>
 ungroup() |>
 dplyr::select(-year) 
head(tlong1)
```

Then we apply the "speciesdiv" function and we add back the year and run columns to have the information.

```{r ex70, eval=FALSE, message = FALSE, warning=FALSE}

div1<-data.frame(speciesdiv(tlong1)) |> mutate(year=unique(tree1$year),
 run=name1) 
head(div1)
```

We make the same steps for the other simulation results (tree2).

```{r ex71, eval=FALSE, message = FALSE, warning=FALSE}
tlong2<-tree2 |>
 group_by(year, species) |> summarise(N=n()) |>
 pivot_wider(id_cols='year', names_from='species',values_from='N', values_fill = 0) |>
 ungroup() |>
 dplyr::select(-year) 

div2<-data.frame(speciesdiv(tlong2)) |> mutate(year=unique(tree2$year),
 run=name2) 

```

We merge them all together and make a plot.

```{r ex72, eval=FALSE, message = FALSE, warning=FALSE}

tlong2<-tree2 |>
 group_by(year, species) |> summarise(N=n()) |>
 pivot_wider(id_cols='year', names_from='species',values_from='N', values_fill = 0) |>
 ungroup() |>
 dplyr::select(-year) 

div2<-data.frame(speciesdiv(tlong2)) |> mutate(year=unique(tree2$year),
 run=name2) 
div<-rbind(div1,div2)

g1<-ggplot(div, aes(year, Shannon , color=run))+
 geom_line(lwd=1.5) +
 labs(x = "Year",y="Shannon index")+theme_bw()

g2<-ggplot(div, aes(year, GiniSimpson , color=run))+
 geom_line(lwd=1.5) +
 labs(x = "Year",y="Gini-Simpson index")+theme_bw()
grid.arrange(g1,g2)
```

We can calculate some additional biodiversity indices using the *treespat* package developed by Francesco Chianucci (fchianucci\@gmail.com).

You can install it using devtools:

```{r ex73, eval=FALSE, message = FALSE, warning=FALSE}
devtools::install_gitlab('fchianucci/treespat')
```

Then, we are ready to use it! We can calculate:

-   Diameter dominance: ADD HERE
-   Diameter differentiation: ADD HERE
-   Stand Complexity Index (SCI): ADD HERE
-   Mingling: ADD HERE

Calculate the indices based on the reference run, then based on the scenario. For each index we add extra columns with the index name, and run name for further analyses.

```{r ex74, eval=FALSE, message = FALSE, warning=FALSE}
library(treespat)

# diameter dominance
# diameter differentiation:
# Stand Complexity Index (SCI):
# mingling
 
ddom<-data.frame(DDOM(tree1, .x = x, .y = y,.mark = dbh, xmax = 100, ymax = 100, 
 max.k = 4, shape='square', .groups=c('year')) |> 
 mutate(index="DDOM", name="Diameter dominance", run=name1))
head(ddom)

diff<-data.frame(DIFF(tree1, .x = x, .y = y,.mark = dbh, xmax = 100, ymax = 100,
 max.k = 4, shape='square', .groups=c('year')) |> 
 mutate(index="DIFF", name="Diameter differentiation", run=name1))
head(diff)

sci<-data.frame(SCI(tree1, .x = x, .y = y, .mark = dbh, .groups=c('year')) |> 
 mutate(index="SCI", name="Stand Complexity Index", run=name1) )
head(sci)

#ming<-MING(tree1, .x = x, .y = y, .species = species, xmax = 100, ymax = 100,
# max.k = 4, shape='square', .groups=c('year')) |> 
# mutate(index="MING", name="Mingling", run=name1)

indices1<-rbind(ddom |> rename(value=DBH.DOM),
 diff |> rename(value=DIFF),
 sci[,-c(3,4)] |> rename(value=mean_SCI) )#this has more columns we need the first two
```

We calculated each index as separate variable and then merged them into indices1. Here I renamed the column names to have it all "value", for easier plotting later on. (each line has the information on which run and which index is the value) We do the same for the scenario simulation, we merge them together and make the plotting.

```{r ex75, eval=FALSE, message = FALSE, warning=FALSE}
ddom<-data.frame(DDOM(tree2, .x = x, .y = y,.mark = dbh, xmax = 100, ymax = 100, 
 max.k = 4, shape='square', .groups=c('year')) |> 
 mutate(index="DDOM", name="Diameter dominance", run=name2))


diff<-data.frame(DIFF(tree2, .x = x, .y = y,.mark = dbh, xmax = 100, ymax = 100,
 max.k = 4, shape='square', .groups=c('year')) |> 
 mutate(index="DIFF", name="Diameter differentiation", run=name2))

sci<-data.frame(SCI(tree2, .x = x, .y = y, .mark = dbh, .groups=c('year')) |> 
 mutate(index="SCI", name="Stand Complexity Index", run=name2))


#ming<-MING(tree2, .x = x, .y = y, .species = species, xmax = 100, ymax = 100,
# max.k = 4, shape='square', .groups=c('year')) |> 
# mutate(index="MING", name="Mingling", run=name2)

indices2<-rbind(ddom |> rename(value=DBH.DOM),
 diff |> rename(value=DIFF),
 sci[,-c(3,4)] |> rename(value=mean_SCI) )

indices<-rbind(indices1,indices2)

ggplot(indices, aes(x=year, y=value, color=run))+
 geom_line(lwd=1)+
 facet_wrap(~name, ncol=2, scales="free")+
 theme_bw() 
```

*ADD interpretation*

### Question B - Group 4 {#sec-B_4}

-   How the species distribution and total living biomass C content changing in time on Plot 4? Compare 0 year and 100 year status in the reference case and in the case of your scenario(s)!

Run the model as it is described in the previous chapters to have at least 2 simulations completed: one with reference conditions and one scenarios with some changes in the environment. Check if you have the output files in the output folder: *iLand_simulations/output/*. If you manage to simualate 2 scenarios, you can expand the code to have file3, and 3rd from each variable, or make the comparison in 2 step always comparing one scenario to the reference conditions at the time. Open the *summerSchoolExerciseProcessBased.Rproj* project in R studio and start working there.

Read in the *landscape* output table from two outputs you have for your plot:

```{r ex76, eval=FALSE, message = FALSE, warning=FALSE}

file1<-"../iLand_simulations/output/Output_plot4.sqlite"
file2<-"../iLand_simulations/output/Output_plot4_4deg_20percdrier.sqlite"

# Give some name for the three simulations.
name1<-"reference"
name2<-"4deg_20percdrier"

# Read in data using the RSQLite package 
sqlite.driver <- dbDriver("SQLite")

# We will work with "landscape" table and tree-scale data:
db1 <- dbConnect(sqlite.driver, dbname = file1) # connect to the file1
landscape1<- dbReadTable(db1,"landscape")
dbDisconnect(db1) # disconnect to the file1

db2 <- dbConnect(sqlite.driver, dbname = file2) # connect to the file2
landscape2<- dbReadTable(db2,"landscape")
dbDisconnect(db2)

```

Merge the data from the three files together and make a column which tells which comes from which simulation, and study the table. The column "run" will support the plotting where we can use facets in ggplot.

```{r ex77, eval=FALSE, message = FALSE, warning=FALSE}

landscape<-rbind(landscape1 |> mutate(run=name1) , 
 landscape2 |> mutate(run=name2))

head(landscape)
```

We can see that the output is given for each year and each species in our 1ha area. Plot the living carbon (total_carbon_kg) in time, coloring by species. We give a unified species coloring in the begining. Plot number of trees and mean diameter. Carbon and number of trees can be plotted in an additive way, but for mean dbh we do line plot per species.

```{r ex78, eval=FALSE, message = FALSE, warning=FALSE}

cols.all=c( "rops"="#e0e0e0","acpl"="#A9A9A9","alin"="#696969","alvi"="#2e2e2e",
 "bepe"="#fadfad","casa"="#7eeadf","coav"="#20c6b6","tipl"="#645394", 
 "ulgl"="#311432","saca"="#D8BFD8","soar"="#DDA0DD","soau"="#BA55D3",
 "pice"="#D27D2D","pini"="#a81c07","algl"="#2ECBE9","tico"="#128FC8", 
 "potr"="#00468B","poni"="#5BAEB7","frex"="#fe9cb5","cabe"="#fe6181",
 "acps"="#fe223e","lade"="#FFFE71","abal"="#FFD800", "pisy"="#A4DE02",
 "fasy"="#76BA1B","piab"="#006600","quro"="#FF7F00", "qupe"="#FF9900", 
 "qupu"="#CC9900")

# We set here the order of the run categories for the table, to have the first
#run first and then the second. (left-right of the plots)
landscape$run<-factor( landscape$run, levels=c(name1,name2))

# Plot the living carbon content, to have tonnes/ha, we divide total_carbon_kg by 1000.
g1<-ggplot(landscape, aes(year, total_carbon_kg/1000 , fill=factor(species)))+
 geom_area() +
 scale_fill_manual(values=cols.all, guide=guide_legend(reverse=TRUE))+
 facet_wrap(~run, nrow=1)+
 labs(x = "Year",y="Living C t/ha",fill = "Species")+
 theme_bw()

g2<-ggplot(landscape, aes(year, count_ha , fill=factor(species)))+
 geom_area() +
 scale_fill_manual(values=cols.all, guide=guide_legend(reverse=TRUE))+
 facet_wrap(~run, nrow=1)+
 labs(x = "Year",y="Number of trees per ha",fill = "Species")+
 theme_bw()

grid.arrange(g1,g2, ncol=1)

g3<-ggplot(landscape, aes(year, dbh_avg_cm , color=factor(species)))+
 geom_line(lwd=1) +
 scale_color_manual(values=cols.all, guide=guide_legend(reverse=TRUE))+
 facet_wrap(~run, nrow=1)+
 labs(x = "Year",y="Mean dbh",fill = "Species")+
 theme_bw()
print(g3)
```

We can see that the forest is growing, it accumulates more and more carbon. We do not have management intervention. Number of trees are increasing as the regeneration layer develops to adult trees (higher than 4m). The species-specific graphs for avg dbh indicates that some species do not have successful regeneration under the scenario. Beech start to dominate and other species do not have the drop in the avg dbh due to regeneration. Calculate the stored C amount in the initial year (year==0) and the last year (year==100)!

```{r ex79, eval=FALSE, message = FALSE, warning=FALSE}
livingC0<-data.frame(landscape |> filter(year==0) |> group_by(run) |> 
 summarize(sum.livingC=sum(total_carbon_kg/1000)) )
print(livingC0)

livingC100<-data.frame(landscape |> filter(year==100) |> group_by(run) |> 
 summarize(sum.livingC=sum(total_carbon_kg/1000)) )
print(livingC100)
```

The initial conditions are same for the runs, but they are ending up at different C levels.

Calculate the stored C amount PER SPECIES in the initial year (year==0) and the last year (year==100)

```{r ex80, eval=FALSE, message = FALSE, warning=FALSE}
species.livingC0<-data.frame(landscape |> filter(year==0) |> group_by(run, species) |> 
 summarize(livingC=sum(total_carbon_kg/1000)) )
print(species.livingC0)

species.livingC100<-data.frame(landscape |> filter(year==100) |> group_by(run, species) |> 
 summarize(livingC=sum(total_carbon_kg/1000)) )
print(species.livingC100)
```

Calculate the species proportions based on the stored C amount in the initial year (year==0) and the last year (year==100) For this we need the total C amount and the species-specific C amount.

```{r ex81, eval=FALSE, message = FALSE, warning=FALSE}
LC0<-left_join(species.livingC0, livingC0, by="run" )
LC0<-data.frame(LC0 |> mutate(spec.prop=livingC/sum.livingC, year=0))
print(LC0)

LC100<-left_join(species.livingC100, livingC100, by="run" )
LC100<-data.frame(LC100 |> mutate(spec.prop=livingC/sum.livingC, year=100))
print(LC100)

```

Put the two tables together and visualize the results!

```{r ex82, eval=FALSE, message = FALSE, warning=FALSE}
LC<-rbind(LC0,LC100)

LC$run<-factor( LC$run, levels=c(name1,name2))

ggplot(LC, aes(fill=species, y=livingC , x=factor(year))) + 
 geom_bar(position="stack", stat="identity")+
 scale_fill_manual(values=cols.all)+
 facet_wrap(~run)+
 ylab("Living C absolute values")+
 theme_bw()




ggplot(LC, aes(fill=species, y=spec.prop, x=factor(year))) + 
 geom_bar(position="stack", stat="identity")+
 scale_fill_manual(values=cols.all)+
 facet_wrap(~run)+
 ylab("Species proportion")+
 theme_bw()

```

# Empirical modeling

In the empirical modelling we will cover two examples of creating two models based on observed data. We will use two approaches Generalized Linear Models (GLMs) and Boosted Regression trees (BRTs). Please take all the results with a grain of salt, we are making very generalized statements from a limited data set, and we are not getting into the details of how each of the models should be assessed; the goal here is that you learn how observed data can be used to create models that help you to understand the data and relationships better.

## Data

We will work with one dataset derived from the inventory developed to assess forest structure and deadwood properties of six representative forest areas in the Czech Republic [@hosek]. This dataset collects observations of the presence /absence of certain species of biodiversity importance across 99 plots.

The data was collected from square sampling plots (2500 m2 each) in six forested Czech Republic regions. These regions are representative of the main bio-regions and elevation range of forests, considering their importance in territorial representation, forestry, and ecology. The inventory sampled for biodiversity variables such as the presence/absence of different species of birds, Tracheophyta, bryophytes, fungi, lichens, and beetles.

The dataset has been generously provided by Jeňýk Hofmeister at the Czech University of Life Sciences Prague (jenyk.hofmeister\@email.cz) to be used in the context of this exercise. It should not be used for other purposes or be further distributed. If you want to use this data or learn more about it, please get in touch with Jeňýk Hofmeisterhere: jenyk.hofmeister\@email.cz.

The data you can download for this exercise is an aggregated summary of the original data, some aspects have been modified from the observed data, so the results you will obtain will only partially match the observed reality. This data is very similar in structure and observed variables to the one you collected in this summer school. The idea is to move from data collection, analysis to this part, where you use the data to create a model.

### Data description {#sec-dataDescription}

These are the variables available in the data

-   `longitud`: longitude of the plot location
-   `latitude`: latitude of the plot location
-   `forestManagementType`: forest management type applied in this plot
-   `forestStructure`: current forest structure in the plot
-   `slope`: slope of the plot
-   `A.pseudoplatanus`: proportion of this tree species in the plot in volume
-   `F.sylvatica`: proportion of this tree species in the plot in volume
-   `L.decidua`: proportion of this tree species in the plot in volume
-   `Q.robur`: proportion of this tree species in the plot in volume
-   `S.aucuparia` : proportion of this tree species in the plot in volume
-   `B.pendula`: proportion of this tree species in the plot in volume
-   `P.abies`: proportion of this tree species in the plot in volume
-   `P.sylvestris`: proportion of this tree species in the plot in volume
-   `F.excelsior`: proportion of this tree species in the plot in volume
-   `A.alba`: proportion of this tree species in the plot in volume
-   `A.platanoides`: proportion of this tree species in the plot in volume
-   `T.cordata`: proportion of this tree species in the plot in volume
-   `S.racemosa`: proportion of this tree species in the plot in volume
-   `U.glabra`: proportion of this tree species in the plot in volume
-   `S.nigra`: proportion of this tree species in the plot in volume
-   `P.alba`: proportion of this tree species in the plot in volume
-   `U.minor`: proportion of this tree species in the plot in volume
-   `S.caprea`: proportion of this tree species in the plot in volume
-   `C.betulus`: proportion of this tree species in the plot in volume
-   `P.nigra`: proportion of this tree species in the plot in volume
-   `Q.petraea`: proportion of this tree species in the plot in volume
-   `S.torminalis`: proportion of this tree species in the plot in volume
-   `A.campestre`: proportion of this tree species in the plot in volume
-   `P.strobus`: proportion of this tree species in the plot in volume
-   `Q.rubra`: proportion of this tree species in the plot in volume
-   `volAllha`: total volume in the plot
-   `GiniDBH`: Gini index calculated to assess the forest structural diversity in diameter sizes, higher values indicate more structural heterogeneity; lower values indicate more homogeneous stands
-   `ShannonIndexTreeSpp`: The Shannon index is way to measure the diversity of tree species in the plot
-   `Tracheophyta_rich`: Species richness across Tracheophyta species
-   `Birds_rich`: Species richness across Birds species
-   `Bryophytes_rich` : Species richness across Bryophytes species
-   `Fungi_rich`: Species richness across Fungi species
-   `Lichens_rich`: Species richness across Lichens species
-   `Beetles_rich`: Species richness across Beetles species
-   `dendrocoposMajor`: presence / absence of Dendrocopos major
-   `certhia`: presence / absence of Certhia familiaris
-   `bryophitaNumObs`: number of observed Bryophytes species
-   `birdNumObs`: number of observed Bird species
-   `PlotID`: ID number for the plot

## Species description

### Species 1 - Bryophytes

Bryophytes constitute an important and permanent component of the forest flora and diversity. They colonize various substrates, which are unsuitable for vascular plants, because of low light intensity or low nutrient level, such as deadwood, bark, rocks, and open soil. They provide shelter habitats, food, and nest material for many animals.

In forests, different ecological guilds of bryophytes can be distinguished by the substrate on which they are growing, including terricolous, lignicolous, corticolous and saxicolous species that occur on soil, deadwood, bark of living trees and shrubs, or rocks, respectively. As diversity and quality of these substrates is affected by forest management, bryophytes are suitable indicators for the effect of management on forest conditions. Especially typical woodland bryophytes, which are strictly depending on forest conditions. It is interesting to better understand the relation of forest management effects on bryophytes and some studies have already demonstrated their sensitivity to management practices.

### Species 2 - Great spotted woodpecker (**Dendrocopos major**)

The great spotted woodpecker (*Dendrocopos major*) is a medium-sized woodpecker with pied black and white plumage and a red patch on the lower belly. It is found in a wide variety of woodlands, broadleaf, coniferous or mixed forests. The great spotted woodpecker spends much of its time climbing trees. It a quite generalist bird species.

### Species 3 - Eurasian treecreeper

The Eurasian treecreeper or common treecreeper (Certhia familiaris) is a small passerine bird. It prefers mature trees, and in most of Europe, it tends to be found mainly in coniferous forest, especially spruce and fir.

## Models

### Generalized Linear Models (GLMs)

We propose to use a generalized linear model (GLM) to understand the abundance of different bryophytes species in the 99 plots. Count data often conform to a Poisson distribution; in this case, we have a count of the number of species recorded at each plot.

Fitting a Poisson GLM in R is similar to analyzing covariance (or linear model), except that we now need to use the glm function. To run a GLM, we need to provide one extra piece of information beyond that required for a linear model: the family of models we want to use. In this case, we want a Poisson family, family=poisson.

### Boosted regression trees (BRTs) {#sec-modelBRT}

Boosted regression trees (BRT) are a combination of two powerful statistical techniques: boosting and regression trees. Boosting is a machine learning technique similar to model averaging, where the results of several competing models are merged. Unlike model averaging, however, boosting uses a forward, stage-wise procedure, where tree models are fitted iteratively to a subset of the training data. Subsets of the training data used at each iteration of the model fit are randomly selected without replacement, where the proportion of the training data used is determined by the modeler, this is defined with the "bag fraction" parameter. This procedure, known as stochastic gradient boosting, introduces an element of stochasticity that improves model accuracy and reduces overfitting [@elith2008].

The BRT model calibration is defined by four parameters:

-   the `learning rate` (or shrinkage parameter): The learning rate determines the contribution of each new tree to the growing model, and it is always substantially lower than 1, higher values being related to faster learning.

-   the `bag fraction`: The bag fraction provides in- formation on which fraction of the entire data should be drawn randomly to fit the new tree. This parameter includes a random probabilistic component, making each run model different, and is aimed at improving model accuracy, speed of model creation, and the reduction of overfitting [@friedman].

-   the `tree complexity`: Tree complexity controls the number of fitted interactions among variables, and determines the number of splits in each tree; for example, a value of 1 will present only one split, meaning that the model does not consider interactions; a value of 2 will result in two splits, and two interactions.

-   The `number of trees` required for optimal prediction: The optimal number of trees is selected based on the three previous parameters. The values fitted by the final model are computed as the sum of all of the predictions of the trees, multiplied by their respective learning rates.

## The exercise

### The project folder

All the project is available in a github repository. You can download the project with this document, code, the `.rproj` and the correct folder structure in [here \[2\]](https://github.com/oldiya/summerSchoolExercise).

\[2\] https://github.com/oldiya/summerSchoolExercise

In this project you will find a folder called `code` where the codes for each question are storaged. A folder called `data` where you have to storage the data that you have downloaded. A folder called `exercise`, that contains this document and all the required files to build it.

### Download the data

You can download the data in [here \[1\]](https://polybox.ethz.ch/index.php/s/qERYKjzmFTr81Sq)

\[1\] https://polybox.ethz.ch/index.php/s/qERYKjzmFTr81Sq

Our recommendation is that you follow this folder structure and you put the data in the folder data of the project and the `.rproj` into the main folder. If you decide to organized things in a different way then you will have to change the path to the code provided to load the data in the section "Explore the data"

![](images/folderStruc.png){width="300"}

### Explore the data

You can load the data in R by doing:

```{r load data, message=FALSE}
observations <- read.csv(here::here("data/observations.csv"))
```

Once you have obtained the data, your next step is to explore it. It is important to carefully analyze the structure of the data and understand its meaning. Each variable must be examined closely, along with the data structure. Remember that each row in this dataset represents one plot, identified by its `PlotID`, and each column represents one variable.

You can explore each of the variables by doing:

```{r explore data }
str(observations)
```

You have a description of each of the variables in the section @sec-dataDescription.

You could do further analysis by exploring the data correlations and you can even plot them to explore their values and ranges better. During this process you should start thinking:

-   What am I trying to understand with this model? (your question)
-   What variables are important to answer my question?

You could for example explore the behavior of the variables by plotting a scatterplot:

```{r explore data 2, fig.width = 9, fig.height = 9}
pairs(~F.sylvatica + P.sylvestris + latitude + volAllha +  GiniDBH + ShannonIndexTreeSpp + Bryophytes_rich, 
      data = observations, main = "Scatterplot Matrix")
```

You can also create individual scatterplots or histograms for a variable of interest, for example:

```{r example scatterplot}
#Divide the screen in 1 line and 3 columns
par(mfrow = c(1, 2), oma = c(0, 2, 0, 0)) 
 
#Make the margin around each graph a bit smaller
par(mar = c(4, 4, 2, 2))
# Histogram and Scatterplot
hist(observations$bryophitaNumObs, main = "", breaks = 10,
     col = rgb(0.3, 0.5, 1, 0.4) , 
     xlab = "Number of observed bryophita")
plot(y = observations$bryophitaNumObs, 
     x = observations$GiniDBH,
     main = "" , pch = 20, cex = 0.4, col = rgb(0.3, 0.5, 1, 0.4), 
     xlab = "Ginni index", ylab = "Number of observed bryophita" )
```

### Question C - Group 1 {#sec-C_1}

-   Does a more diverse forest in structure and composition have more Bryophytes species?

#### Fitting a Poisson GLM in R

During your data exploration, you should have selected your response variable, `bryophitaNumObs`. In this case, since we are trying to understand forest structure and composition, you should also choose explanatory variables for that, such as `GiniDBH,` which indicates the forest structural diversity in diameter sizes; higher values indicate more structural heterogeneity, and lower values indicate more homogeneous stands, or the `ShannonIndexTreeSpp` which assess the diversity of tree species in the plot.

We could start by only looking at how the forest structural diversity affects the number of Bryophytes species that we have in a plot. You can create a GLM model with `bryophitaNumObs` as the response variable and `GiniDBH` as an explanatory variable. You will use the function glm in R and the `family = poisson`. You can see how to create and see this model here:

```{r fit glm struct11}
bryoModel1 <- glm(bryophitaNumObs ~ GiniDBH,
                 family = poisson,
                 data = observations)

summary(bryoModel1)
```

Here you can see that the coefficient table produced by a GLM is very similar to a linear model. The intercept tells us the estimated value of the response variable when the continuous explanatory variables (here, just the Gini index) has a value of 0. We then also have coefficients describing the slope of the relationship with our continuous explanatory variables. We can see here that the number of Bryophytes species appears to show a positive relationship with the Gini index, which means that increasing structural diversity in tree diameter sizes has a positive relationship with the number of Bryophytes species in the plot.

We are also interested in understanding the relationship between the number of Bryophytes species and the tree species diversity; we can now try to add this variable into the model and see if it helps us to understand things. You can do that by adding the variable `ShannonIndexTreeSpp` to the model:

```{r fit glm struct12}
bryoModel2 <- glm(bryophitaNumObs ~ GiniDBH + ShannonIndexTreeSpp,
                 family = poisson,
                 data = observations)

summary(bryoModel2)
```

Here we can see that the variable Shannon index also has a positive relationship with the number of Bryophytes species in the plot, but its effect is much smaller. We can also observe that this variable is not significant. This does not mean it is wrong to add this variable because we want to understand its effect, but keeping this variable in the model depends on what you're trying to do and what "reality" is. Adding variables that are not needed will not help your model (particularly your estimates) but also might not matter much (e.g., predictions). However, removing actual variables can create a useless model even if they don't meet significance.

Variable selection is a long and complicated topic. Some general rules of thumb include: (1) Include the variable if it is of interest, (2) Include the variable if you have some prior knowledge that it should be relevant. This can be misleading because it's a confirmation bias, but in most cases, this makes sense. (3) If you want a model that can generalize to many cases, you should favor fewer variables.

#### Explanatory Power of the model

When we ran linear models, we used the coefficient of determination, or R^2^ to assess how much of the variability in our response variable is explained by a given model. R^2^ is based on the sums of squares of our model, and so cannot be calculated for GLMs. Instead, we can calculate the deviance explained by our model:

```{r deviance explained by our model1}

# Extract the null and residual deviance from the model
dev.null <- bryoModel1$null.deviance
dev.resid <- bryoModel1$deviance

# Calculate the deviance explained by the model
dev.explained <- (dev.null - dev.resid)/dev.null

# Round to 3 decimal places
dev.explained <- round(dev.explained, 3)

dev.explained

```

Variability in forest structure (Gini index) explain 15% of the variation in Bryophytes species richness in this study. That is an ok explanatory power for a very simple model of a complex ecological system (many factors determine the species richness for Bryophytes and we are attempting to explain everything with just one variable).

#### Model Assumptions

For Poisson GLMs, there is one further assumption that we have not encountered before. If data follow a Poisson distribution, then the mean of the distribution is equal to the variance. Accordingly, a Poisson distribution is represented by just one parameter λ, which describes both the mean and the variance of the distribution.

Count data in ecology are often **overdispersed**, where the variance is greater than the mean. This violates the assumption of a Poisson GLM, and means that any statistics that we calculate from the model may be unreliable.

We can get an indication of whether a model is over-dispersed by inspecting the model summary. As a rule of thumb, if the response variable conforms to a true Poisson distribution, we expect the residual deviance to be approximately equal to the residual degrees of freedom. If the deviance is much greater than the degrees of freedom, this indicates over-dispersion. This is the case in our models.

To check the model assumptions in a GLM is not as straight forward as with a linear model. This is because classical residuals are not expected to behave in the same way for GLMs. We can use the DHARMa package in R for working with GLMs, which uses a simulation-based approach to compare the residuals from the actual model with the expectation if the model is behaving normally:

```{r model assumptions1, fig.width = 9, fig.height = 6}
# Simulate residuals 
simResids <- DHARMa::simulateResiduals(bryoModel1)

# Generate plots to compare the model residuals to expectations
plot(simResids)
```

These plots show us that this model is not behaving as we would expect in terms of homogeneity of variance and distribution of residuals. A follow up to this would be to try alternatives to deal with over-dispersed count data in GLMs such as fit a quasi-Poisson GLM or a negative binomial GLM. Unfortunately we do not have time to continuou in this exercise.

### Question D - Group 1 {#sec-D_1}

-   Is the number of Briophites species affected by forest management type and the forest structural diversity?

#### Fitting a Poisson GLM in R

Fitting a Poisson GLM in R is very similar to fitting an analysis of covariance (or linear model), except that now we need to use the glm function. To run a GLM, we need to provide one extra piece of information beyond that needed for a linear model: the family of model we want to use. In this case, we want a Poisson family.

We could start by only looking at how the forest structural diversity affects the number Bryophytes species that we have in a plot. You can do this by creating a GLM model which has `bryophitaNumObs` as response variable and `GiniDBH` as explanatory variable. For that you will use the function `glm` in R and use the `family = poisson`. You can see how to create and see this model here:

```{r fit glm struct21}
bryoModel1 <- glm(bryophitaNumObs ~ GiniDBH,
                 family = poisson,
                 data = observations)

summary(bryoModel1)
```

Here you can see that the coefficient table produced by a GLM is very similar to a linear model. The intercept tells us the estimated value of the response variable when the continuous explanatory variables (here just Gini index) have a value of 0. We then also have coefficients describing the slope of the relationship with our continuous explanatory variables. We can see here that the bryophita numbers appears to show a positive relationship with Gini index, which means that increasing structural diversity in trees diameter sizes has a positive relationship with the number of bryophita species in the plot.

We are also interested in understanding the relationship with of the number of observed Bryophytes species and forest management, we can now try to add this variable into the model.

```{r fit glm struct22}
bryoModel2 <- glm(bryophitaNumObs ~ forestManagementType,
                 family = poisson,
                 data = observations)

summary(bryoModel2)
```

The intercept here tells us the estimated value of the response variable when the reference groups in our grouping (categorical) variables (here for retention clear-cutting). We then also have coefficients describing the slope of the relationship with our continuous explanatory variables, and coefficients giving the estimated difference in the response variable for non-reference groupings. We can see here that number of bryophites species appears to show a negative relationship with simple clearcutting, and appears to have a positive relationship with unmanaged and retention clear-cutting.

The type simple clearcutting it appears to be no significant, which only tell us about the pairwise differences between the levels. To test whether the categorical predictor, as a whole, is significant is equivalent to testing whether there is any heterogeneity in the means of the levels of the predictor. When there are no other predictors in the model, this is a classical [ANOVA](http://en.wikipedia.org/wiki/Analysis_of_variance) problem.

#### Explanatory Power of the model

When we ran linear models, we used the coefficient of determination, or R^2^ to assess how much of the variability in our response variable is explained by a given model. R^2^ is based on the sums of squares of our model, and so cannot be calculated for GLMs. Instead, we can calculate the the deviance explained by our model:

```{r deviance explained by our model2}

# Extract the null and residual deviance from the model
dev.null <- bryoModel1$null.deviance
dev.resid <- bryoModel1$deviance

# Calculate the deviance explained by the model
dev.explained <- (dev.null - dev.resid)/dev.null

# Round to 3 decimal places
dev.explained <- round(dev.explained, 3)

dev.explained

```

Variability in forest structure (Gini index) explain 15% of the variation in bryophita species richness in this study system. That is an ok explanatory power for a very simple model of a complex ecological system (many factors determine the species richness for bryophitas and we are attempting to explain everything with one variable).

#### Model Assumptions

For Poisson GLMs, there is one further assumption that we have not encountered before. If data follow a Poisson distribution, then the mean of the distribution is equal to the variance. Accordingly, a Poisson distribution is represented by just one parameter λ, which describes both the mean and the variance of the distribution.

Count data in ecology are often ***overdispersed***, where the variance is greater than the mean. This violates the assumption of a Poisson GLM, and means that any statistics that we calculate from the model may be unreliable.

We can get an indication of whether a model is over-dispersed by inspecting the model summary. As a rule of thumb, if the response variable conforms to a true Poisson distribution, we expect the residual deviance to be approximately equal to the residual degrees of freedom. If the deviance is much greater than the degrees of freedom, this indicates over-dispersion. This is the case in our models.

To check the model assumptions in a GLM is not as straight forward as with a linear model. This is because classical residuals are not expected to behave in the same way for GLMs. We can use the DHARMa package in R for working with GLMs, which uses a simulation-based approach to compare the residuals from the actual model with the expectation if the model is behaving normally.

```{r model assumptions2 , fig.width = 9, fig.height = 6}
# Simulate residuals 
simResids <- DHARMa::simulateResiduals(bryoModel1)

# Generate plots to compare the model residuals to expectations
plot(simResids)
```

These plots show us that this model is not behaving as we would expect in terms of homogeneity of variance and distribution of residuals. A follow up to this would be to try alternatives to deal with over-dispersed count data in GLMs such as fit a quasi-Poisson GLM or a negative binomial GLM. Unfortunately we do not have to continuou in this exercise.

### Question C - Group 2 {#sec-C_2}

-   Does a more diverse forest in structure and composition have more bird species?

#### Fitting a Poisson GLM in R

During your data exploration you should have selected your response variable: `bryophitaNumObs`. In this case since we are trying to understand forest structure and composition you should also select explanatory variables for that such as `GiniDBH` which indicates the forest structural diversity in diameter sizes, higher values indicate more structural heterogeneity and lower values indicate more homogeneous stands, or the `ShannonIndexTreeSpp` which assess the diversity of tree species in the plot.

We could start by only looking at how the forest structural diversity affects the number Bryophytes species that we have in a plot. You can do this by creating a GLM model which has `bryophitaNumObs` as response variable and `GiniDBH` as explanatory variable. For that you will use the function `glm`in R and use the `family = poisson`. You can see how to create and see this model here:

```{r fit glm struct 31}
birdModel1 <- glm(birdNumObs ~ GiniDBH,
                 family = poisson,
                 data = observations)

summary(birdModel1)
```

Here you can see that the coefficient table produced by a GLM is very similar to a linear model. The intercept tells us the estimated value of the response variable when the continuous explanatory variables (here just Gini index) has a value of 0. We then also have coefficients describing the slope of the relationship with our continuous explanatory variables. We can see here that the number of bird species appears to show a positive relationship with Gini index, which means that increasing structural diversity in trees diameter sizes has a positive relationship with the number of bird species in the plot.

We are also interested in understanding the relationship with the number of bird species and the trees species diversity, we can now try to add this variable into the model and see if it help us to understand things. You can do that by adding the variable `ShannonIndexTreeSpp` into the model

```{r fit glm struct32}
birdModel2 <- glm(birdNumObs ~ GiniDBH + ShannonIndexTreeSpp,
                 family = poisson,
                 data = observations)

summary(birdModel2)
```

Here we can see that the variable Shannon index also has a positive relationship with the number of bird species in the plot but its effect is much smaller. We can also observed that this variable it is not significant and that including this variable also made Gini index variable not significant. This does not mean that is wrong to add this variable, because we want to understand its effect, but keeping this variable in the model or not it depends on what you're trying to do, and what "reality" is. Adding variables that are not needed will not help your model (particularly your estimates), but also might not matter much (e.g. predictions). However, removing variables that are real, even if they don't meet significance, can create a useless model.

Variable selection is a long and complicated topic. some general rules of thumb include: (1) Include the variable if it is of interest, (2) Include the variable if you have some prior knowledge that it should be relevant. This can be misleading, because it's a confirmation bias, but in most cases this makes sense. (3) If you want a model that can generalize to many cases, you should favor fewer variables.

#### Explanatory Power of the model

When we ran linear models, we used the coefficient of determination, or R^2^ to assess how much of the variability in our response variable is explained by a given model. R^2^ is based on the sums of squares of our model, and so cannot be calculated for GLMs. Instead, we can calculate the the deviance explained by our model:

```{r deviance explained by our model3}

# Extract the null and residual deviance from the model
dev.null <- birdModel1$null.deviance
dev.resid <- birdModel1$deviance

# Calculate the deviance explained by the model
dev.explained <- (dev.null - dev.resid)/dev.null

# Round to 3 decimal places
dev.explained <- round(dev.explained, 3)

dev.explained

```

Variability in forest structure (Gini index) explain 8% of the variation in bird species richness in this study. That is an ok explanatory power for a very simple model of a complex ecological system (many factors determine the species richness for birds and we are attempting to explain everything with just one variable).

#### Model Assumptions

For Poisson GLMs, there is one further assumption that we have not encountered before. If data follow a Poisson distribution, then the mean of the distribution is equal to the variance. Accordingly, a Poisson distribution is represented by just one parameter λ, which describes both the mean and the variance of the distribution.

Count data in ecology are often **overdispersed**, where the variance is greater than the mean. This violates the assumption of a Poisson GLM, and means that any statistics that we calculate from the model may be unreliable.

We can get an indication of whether a model is over-dispersed by inspecting the model summary. As a rule of thumb, if the response variable conforms to a true Poisson distribution, we expect the residual deviance to be approximately equal to the residual degrees of freedom. If the deviance is much greater than the degrees of freedom, this indicates over-dispersion. This is the case in our models.

To check the model assumptions in a GLM is not as straight forward as with a linear model. This is because classical residuals are not expected to behave in the same way for GLMs. We can use the DHARMa package in R for working with GLMs, which uses a simulation-based approach to compare the residuals from the actual model with the expectation if the model is behaving normally:

```{r model assumptions3, fig.width = 9, fig.height = 6}
# Simulate residuals 
simResids <- DHARMa::simulateResiduals(birdModel1)

# Generate plots to compare the model residuals to expectations
plot(simResids)
```

These plots show us that this model is not behaving as we would expect in terms of homogeneity of variance and distribution of residuals. A follow up to this would be to try alternatives to deal with over-dispersed count data in GLMs such as fit a quasi-Poisson GLM or a negative binomial GLM. Unfortunately we do not have time to continuou in this exercise.

### Question D - Group 2 {#sec-D_2}

-   Is the number of bird species affected by forest management type and the forest structural diversity?

#### Fitting a Poisson GLM in R

Fitting a Poisson GLM in R is very similar to fitting an analysis of covariance (or linear model), except that now we need to use the glm function. To run a GLM, we need to provide one extra piece of information beyond that needed for a linear model: the family of model we want to use. In this case, we want a Poisson family.

We could start by only looking at how the forest structural diversity affects the number Bryophytes species that we have in a plot. You can do this by creating a GLM model which has `birdNumObs` as response variable and `GiniDBH` as explanatory variable. For that you will use the function `glm` in R and use the `family = poisson`. You can see how to create and see this model here:

```{r fit glm struct41}
birdModel1 <- glm(birdNumObs ~ GiniDBH,
                 family = poisson,
                 data = observations)

summary(birdModel1)
```

Here you can see that the coefficient table produced by a GLM is very similar to a linear model. The intercept tells us the estimated value of the response variable when the continuous explanatory variables (here just Gini index) have a value of 0. We then also have coefficients describing the slope of the relationship with our continuous explanatory variables. We can see here that the bird numbers appears to show a positive relationship with Gini index, which means that increasing structural diversity in trees diameter sizes has a positive relationship with the number of bird species in the plot.

We are also interested in understanding the relationship with of the number of observed bird species and forest management, we can now try to add this variable into the model.

```{r fit glm struct42}
birdModel2 <- glm(birdNumObs ~ forestManagementType,
                 family = poisson,
                 data = observations)

summary(birdModel2)
```

The intercept here tells us the estimated value of the response variable when the reference groups in our grouping (categorical) variables (here for retention clear-cutting). We then also have coefficients describing the slope of the relationship with our continuous explanatory variables, and coefficients giving the estimated difference in the response variable for non-reference groupings. We can see here that number of bird species appears to show a negative relationship with simple clearcutting, unmanaged and a positive relationship with retention clear-cutting.

The type simple clearcutting and unmanaged it appears to be no significant, which only tell us about the pairwise differences between the levels. To test whether the categorical predictor, as a whole, is significant is equivalent to testing whether there is any heterogeneity in the means of the levels of the predictor. When there are no other predictors in the model, this is a classical [ANOVA](http://en.wikipedia.org/wiki/Analysis_of_variance) problem.

#### Explanatory Power of the model

When we ran linear models, we used the coefficient of determination, or R^2^ to assess how much of the variability in our response variable is explained by a given model. R^2^ is based on the sums of squares of our model, and so cannot be calculated for GLMs. Instead, we can calculate the the deviance explained by our model:

```{r deviance explained by our model4}

# Extract the null and residual deviance from the model
dev.null <- birdModel1$null.deviance
dev.resid <- birdModel1$deviance

# Calculate the deviance explained by the model
dev.explained <- (dev.null - dev.resid)/dev.null

# Round to 3 decimal places
dev.explained <- round(dev.explained, 3)

dev.explained

```

Variability in forest structure (Gini index) explain 15% of the variation in bryophita species richness in this study system. That is an ok explanatory power for a very simple model of a complex ecological system (many factors determine the species richness for bryophitas and we are attempting to explain everything with one variable).

#### Model Assumptions

For Poisson GLMs, there is one further assumption that we have not encountered before. If data follow a Poisson distribution, then the mean of the distribution is equal to the variance. Accordingly, a Poisson distribution is represented by just one parameter λ, which describes both the mean and the variance of the distribution.

Count data in ecology are often ***overdispersed***, where the variance is greater than the mean. This violates the assumption of a Poisson GLM, and means that any statistics that we calculate from the model may be unreliable.

We can get an indication of whether a model is over-dispersed by inspecting the model summary. As a rule of thumb, if the response variable conforms to a true Poisson distribution, we expect the residual deviance to be approximately equal to the residual degrees of freedom. If the deviance is much greater than the degrees of freedom, this indicates over-dispersion. This is the case in our models.

To check the model assumptions in a GLM is not as straight forward as with a linear model. This is because classical residuals are not expected to behave in the same way for GLMs. We can use the DHARMa package in R for working with GLMs, which uses a simulation-based approach to compare the residuals from the actual model with the expectation if the model is behaving normally.

```{r model assumptions4 , fig.width = 9, fig.height = 6}
# Simulate residuals 
simResids <- DHARMa::simulateResiduals(birdModel1)

# Generate plots to compare the model residuals to expectations
plot(simResids)
```

These plots show us that this model is not behaving as we would expect in terms of homogeneity of variance and distribution of residuals. A follow up to this would be to try alternatives to deal with over-dispersed count data in GLMs such as fit a quasi-Poisson GLM or a negative binomial GLM. Unfortunately we do not have to continuou in this exercise.

### Question C - Group 3 {#sec-C_3}

-   Is the presence of the Great spotted woodpecker affected by forest density?

#### Fitting a BRT in R

In this case we want to assess the occurrence of certain species across the plots. In other words, we want to assess what is the probability of a certain species with biodiversity interest to be present in a plot based on the variables that describe the forest of that plot. In this case the response variable is `dendrocoposMajor` that represents if the Great spotted woodpecker has been observed in this plot or not.

Then you need to select some variables of interest, after you have explored the data you can decide which variables you want to use to fit this model. We are proposing to select the following variables:

-   `latitude` as proxy for plot location or/and climate

-   `forestManagementType` to assess if different management types have different impact in the presence / absence of Parus major.

-   `volAllha` that is the total volume in the plot, as a proxy of how dense the plot is. Higher volumes will mean that the forest is more dense.

-   `GiniDBH` showing how homogeneous the plot is in trees diameters. A value closer to 1 will mean that indicate more structural heterogeneity, lower values indicate more homogeneous plots.

-   `Birds_rich` are the species richness value calculated for all bird species species, higher value indicate higher species richness for birds.

You can create a vector `selVar` in which you add the names of the selected variables. Then you only take those variables from the data that you will use to create the model.

```{r selectVar}
# Select variables from the dataset for the model
selVar <- c("dendrocoposMajor", "latitude","forestManagementType",
            "volAllha", "GiniDBH",  "ShannonIndexTreeSpp", "Birds_rich")

# Filter the dataset to the selected variables
modelDataSel <- observations[, colnames(observations) %in% selVar]

```

Unfortunately the amount of that we have in this dataset it is not enough to fit a BRT model for these variables. We are going to do an obviously wrong thing for the shake of being able to demonstrate how to fit a BRT model. In the next code you are going to repeat the same dataset multiple times:

```{r data repetition}
modelDataSel <- rbind(modelDataSel, modelDataSel, modelDataSel, modelDataSel,
                      modelDataSel)
```

Now it is important to assess if the variables have the right categories. Variables should be type numeric or factor.

```{r check data}
summary(modelDataSel)

# Two variables are character, we assign to factor instead:
modelDataSel$forestManagementType <- as.factor(modelDataSel$forestManagementType)

```

In the next step you can see how you can run the model with the selected variables and model parameters. You have a description of the models parameters in the @sec-modelBRT . In this example we are going to use the default parameters for the calibration, where learning rate = 0.01 and tree complexity = 1 and cross-validation = 10-fold. However, the bag fraction is changed from the default value, 0.75, to 0.5. As a family we used the Bernoulli family, because we are predicting presence/absence per plot. These data have 495 plots, comprising 350 presence records for the Great spotted woodpecker. You can check these numbers by doing:

```{r check numbers}
table(modelDataSel$dendrocoposMajor)
```

As a first guess you could decide there are enough data to model interactions of reasonable complexity, and a lr of about 0.01 could be a reasonable starting point. You can use the model creation function that steps forward and identifies the optimal number of trees (nt) by doing this:

```{r BRTmodel, message=FALSE, warning=FALSE, results = "hide"}
family <- "bernoulli"

    tc = 1    # tree complexity
    lr = 0.01 # learning rate-shrinkage 
    bag = 0.5 # bag fraction
    
    modelBRT <- dismo::gbm.step(data = modelDataSel,
                          #indices of predictor variables in data
                          gbm.x = 1:6, 
                          #index of response variable in data:
                          gbm.y = 7,  
                          family = family,
                          tree.complexity = tc,
                          learning.rate = lr,
                          bag.fraction = bag)  

```

Running a model such as that described above writes progress reports to the screen, makes a graph, and returns an object containing a number of components. The R console results reports a brief model summary all the values are also retained in the model object.

The model is built with the default 10-fold cross-validation (CV). In the plotted graph the solid black curve is the mean, and the dotted curves 1 standard error, for the changes in predictive deviance (i.e., as measured on the excluded folds of the CV). The red line shows the minimum of the mean, and the green line the number of trees at which that occurs. The final model that is returned in the model object is built on the full data set, using the number of trees identified as optimal.

Ideally, you should invest time in modifying the parameters and finr the parameters that provide the models with the minimum deviance resulting from the best combination of bag, tree complexity and learning rate values. For the shake of limited timing, we will only test here the default values.

#### Model behaviour

You can summarized the model parameters used and the cross validation statistics from the fitted model by doing this:

```{r BRTeval}
# We make a table with the summary statistics  
 results <- data.frame(

# Model parameters
Tree.Complexity = modelBRT$gbm.call$tree.complexity, 
Learning.Rate = modelBRT$gbm.call$learning.rate, 
                 Bag.Fraction = modelBRT$gbm.call$bag.fraction,
                 Interaction.depth = modelBRT$interaction.depth,
                 Shrinkage = modelBRT$shrinkage,
                 N.trees = modelBRT$n.trees,
     
# Cross validation statistics 
     
## mean total deviance
Deviance = modelBRT$self.statistics$mean.resid, # mean residual deviance 

AUC = modelBRT$self.statistics$discrimination, # training data AUC score

Corr = modelBRT$self.statistics$correlation,   # training data correlation
                 
## Cross Validation statistics
                 
# We calculate each statistic within each fold (at the identified optimal number
# of trees that is calculated on the mean change in predictive deviance over all folds), 
#then present here the mean and standard error of those fold-based statistics.
                 
devianceCV = modelBRT$cv.statistics$deviance.mean,  # estimated cv deviance 
devianceCVse = modelBRT$cv.statistics$deviance.se,  # estimated cv deviance se
                 
CorrCV = modelBRT$cv.statistics$correlation.mean,  #cv correlation
CorrCVse = modelBRT$cv.statistics$correlation.se,  #cv correlation se
                 
AUCcv = modelBRT$cv.statistics$discrimination.mean, # cv AUC score
AUCcvSE = modelBRT$cv.statistics$discrimination.se)  # cv AUC score se
                
    
print(t(results))

```

#### Model output analysis

We can look at the relative contribution of each of the predictor variables. The measures are based on the number of time the variable is selected for splitting, weighted by the improvement of the model as a result of each split averaged across all trees. The relative contribution of each of the variables is scaled so the sum is 100%, with higher numbers indicating stronger influence in the response.

```{r varImportance}
# Variables contribution 
modelBRT$contributions 

```

Here we can see that the two variables with the highest influence in the response are `latitude`, and `volAllhsa`.

Now we can evaluate the model behavior via partial dependence plots, showing the effect of each of the variables on the response by accounting for the average effects of all other predictors in the model:

```{r marginallEffects}
    dismo::gbm.plot(modelBRT, n.plots = 6,
             plot.layout = c(2, 3), write.title = F)
```

In this partial dependence plots the predictions are on the scale of f(x). In this case, for the Bernoulli loss the returned value is on the log odds scale. You can see how this plot will look by plotting with the function from the package `gbm` and using the type "response". Since we are interesting in finding out if the forest density has an impact in the presence of the Great spotted woodpecker we can have a look to the plot density variable `volAllha` :

```{r, response}
gbm::plot.gbm(modelBRT, i.var = 3, type = "response", ylab = "Probability of finding a Great spotted woodpecker ")
```

It seems that there is an increase in probability of finding a Great spotted woodpecker with higher forest densities, but the trend it is not very clear. We could also analyse the interaction effects, of density and for example overall bird richness. The model predictions can be obtained for each pair of predictor variables, setting all other predictors to their means.

To plot this pairwise interactions we have to do:

```{r pairwise int, warning=FALSE, message=FALSE}
dismo::gbm.perspec(modelBRT, 3, 6)
```

Here we can see that both increasing bird diversity and forest density provides the highest probabilities for finding the Great spotted woodpecker.

### Question D - Group 3 {#sec-D_3}

-   Is the presence of the Great spotted woodpecker affected by forest diversity?

#### Fitting a BRT in R

In this case we want to assess the occurrence of certain species across the plots. In other words, we want to assess what is the probability of a certain species with biodiversity interest to be present in a plot based on the variables that describe the forest of that plot. In this case the response variable is `dendrocoposMajor` that represents if the Great spotted woodpecker has been observed in this plot or not.

Then you need to select some variables of interest, after you have explored the data you can decide which variables you want to use to fit this model. We are proposing to select the following variables:

-   `latitude` as proxy for plot location or/and climate

-   `forestManagementType` to assess if different management types have different impact in the presence / absence of Parus major.

-   `volAllha` that is the total volume in the plot, as a proxy of how dense the plot is. Higher volumes will mean that the forest is more dense.

-   `GiniDBH` showing how homogeneous the plot is in trees diameters. A value closer to 1 will mean that indicate more structural heterogeneity, lower values indicate more homogeneous plots.

-   `Birds_rich` are the species richness value calculated for all bird species species, higher value indicate higher species richness for birds.

You can create a vector `selVar` in which you add the names of the selected variables. Then you only take those variables from the data that you will use to create the model.

```{r selectVar6}
# Select variables from the dataset for the model
selVar <- c("dendrocoposMajor", "latitude","forestManagementType",
            "volAllha","GiniDBH",  "ShannonIndexTreeSpp", "Birds_rich")

# Filter the dataset to the selected variables
modelDataSel <- observations[, colnames(observations) %in% selVar]

```

Unfortunately the amount of that we have in this dataset it is not enough to fit a BRT model for these variables. We are going to do an obviously wrong thing for the shake of being able to demonstrate how to fit a BRT model. In the next code you are going to repeat the same dataset multiple times:

```{r data repetition6}
modelDataSel <- rbind(modelDataSel, modelDataSel, modelDataSel, modelDataSel,
                      modelDataSel)
```

Now it is important to assess if the variables have the right categories. Variables should be type numeric or factor.

```{r check data6}
summary(modelDataSel)

# Two variables are character, we assign to factor instead:
modelDataSel$forestManagementType <- as.factor(modelDataSel$forestManagementType)

```

In the next step you can see how you can run the model with the selected variables and model parameters. You have a description of the models parameters in the @sec-modelBRT . In this example we are going to use the default parameters for the calibration, where learning rate = 0.01 and tree complexity = 1 and cross-validation = 10-fold. However, the bag fraction is changed from the default value, 0.75, to 0.5. As a family we used the Bernoulli family, because we are predicting presence/absence per plot. These data have 495 plots, comprising 350 presence records for the Great spotted woodpecker. You can check these numbers by doing:

```{r check numbers6}
table(modelDataSel$dendrocoposMajor)
```

As a first guess you could decide there are enough data to model interactions of reasonable complexity, and a lr of about 0.01 could be a reasonable starting point. You can use the model creation function that steps forward and identifies the optimal number of trees (nt) by doing this:

```{r BRTmodel6, message=FALSE, warning=FALSE, results = "hide"}
family <- "bernoulli"

    tc = 1    # tree complexity
    lr = 0.01 # learning rate-shrinkage 
    bag = 0.5 # bag fraction
    
    modelBRT <- dismo::gbm.step(data = modelDataSel,
                          #indices of predictor variables in data
                          gbm.x = 1:6, 
                          #index of response variable in data:
                          gbm.y = 7,  
                          family = family,
                          tree.complexity = tc,
                          learning.rate = lr,
                          bag.fraction = bag)  

```

Running a model such as that described above writes progress reports to the screen, makes a graph, and returns an object containing a number of components. The R console results reports a brief model summary all the values are also retained in the model object.

The model is built with the default 10-fold cross-validation (CV). In the plotted graph the solid black curve is the mean, and the dotted curves 1 standard error, for the changes in predictive deviance (i.e., as measured on the excluded folds of the CV). The red line shows the minimum of the mean, and the green line the number of trees at which that occurs. The final model that is returned in the model object is built on the full data set, using the number of trees identified as optimal.

Ideally, you should invest time in modifying the parameters and finr the parameters that provide the models with the minimum deviance resulting from the best combination of bag, tree complexity and learning rate values. For the shake of limited timing, we will only test here the default values.

#### Model behaviour

You can summarized the model parameters used and the cross validation statistics from the fitted model by doing this:

```{r BRTeval6}
# We make a table with the summary statistics  
 results <- data.frame(

# Model parameters
Tree.Complexity = modelBRT$gbm.call$tree.complexity, 
Learning.Rate = modelBRT$gbm.call$learning.rate, 
                 Bag.Fraction = modelBRT$gbm.call$bag.fraction,
                 Interaction.depth = modelBRT$interaction.depth,
                 Shrinkage = modelBRT$shrinkage,
                 N.trees = modelBRT$n.trees,
     
# Cross validation statistics 
     
## mean total deviance
Deviance = modelBRT$self.statistics$mean.resid, # mean residual deviance 

AUC = modelBRT$self.statistics$discrimination, # training data AUC score

Corr = modelBRT$self.statistics$correlation,   # training data correlation
                 
## Cross Validation statistics
                 
# We calculate each statistic within each fold (at the identified optimal number
# of trees that is calculated on the mean change in predictive deviance over all folds), 
#then present here the mean and standard error of those fold-based statistics.
                 
devianceCV = modelBRT$cv.statistics$deviance.mean,  # estimated cv deviance 
devianceCVse = modelBRT$cv.statistics$deviance.se,  # estimated cv deviance se
                 
CorrCV = modelBRT$cv.statistics$correlation.mean,  #cv correlation
CorrCVse = modelBRT$cv.statistics$correlation.se,  #cv correlation se
                 
AUCcv = modelBRT$cv.statistics$discrimination.mean, # cv AUC score
AUCcvSE = modelBRT$cv.statistics$discrimination.se)  # cv AUC score se
                
    
print(t(results))

```

#### Model output analysis

We can look at the relative contribution of each of the predictor variables. The measures are based on the number of time the variable is selected for splitting, weighted by the improvement of the model as a result of each split averaged across all trees. The relative contribution of each of the variables is scaled so the sum is 100%, with higher numbers indicating stronger influence in the response.

```{r varImportance6}
# Variables contribution 
modelBRT$contributions 

```

Here we can see that the two variables with the highest influence in the response are `latitude`, and `volAllhsa`.

Now we can evaluate the model behavior via partial dependence plots, showing the effect of each of the variables on the response by accounting for the average effects of all other predictors in the model:

```{r marginallEffects6}
    dismo::gbm.plot(modelBRT, n.plots = 6,
             plot.layout = c(2, 3), write.title = F)
```

In this partial dependence plots the predictions are on the scale of f(x). In this case, for the Bernoulli loss the returned value is on the log odds scale. You can see how this plot will look by plotting with the function from the package `gbm` and using the type "response". Since we are interesting in finding out if the forest diversity has an impact in the presence of the Great spotted woodpecker we can have a look to the plot density variable `volAllha` :

```{r, response6}
gbm::plot.gbm(modelBRT, i.var = 5, type = "response", ylab = "Probability of finding a Great spotted woodpecker ")
```

It seems that there is an increase in probability of finding a Great spotted woodpecker with higher forest densities, but the trend it is not very clear. We could also analyse the interaction effects, of forest diversity and for example forest density. The model predictions can be obtained for each pair of predictor variables, setting all other predictors to their means.

To plot this pairwise interactions we have to do:

```{r pairwise int6, warning=FALSE, message=FALSE}
dismo::gbm.perspec(modelBRT, 3, 5)
```

Here we can not see a very clear combined behavior between forest diversity and forest structural diversity in respect to the probabilities for finding the Great spotted woodpecker.

### Question C - Group 4 {#sec-C_4}

-   Is the presence of the Eurasian treecreeper affected by forest density?

#### Fitting a BRT in R

In this case we want to assess the occurrence of certain species across the plots. In other words, we want to assess what is the probability of a certain species with biodiversity interest to be present in a plot based on the variables that describe the forest of that plot. In this case the response variable is `phoenicurus` that represents if the Great spotted woodpecker has been observed in this plot or not.

Then you need to select some variables of interest, after you have explored the data you can decide which variables you want to use to fit this model. We are proposing to select the following variables:

-   `latitude` as proxy for plot location or/and climate

-   `forestManagementType` to assess if different management types have different impact in the presence / absence of Parus major.

-   `volAllha` that is the total volume in the plot, as a proxy of how dense the plot is. Higher volumes will mean that the forest is more dense.

-   `GiniDBH` showing how homogeneous the plot is in trees diameters. A value closer to 1 will mean that indicate more structural heterogeneity, lower values indicate more homogeneous plots.

You can create a vector `selVar` in which you add the names of the selected variables. Then you only take those variables from the data that you will use to create the model.

```{r selectVar7}
# Select variables from the dataset for the model
selVar <- c("certhia", "latitude", "forestManagementType",
            "volAllha", "GiniDBH",  "ShannonIndexTreeSpp", 
            "Birds_rich")

# Filter the dataset to the selected variables
modelDataSel <- observations[, colnames(observations) %in% selVar]

```

Unfortunately the amount of that we have in this dataset it is not enough to fit a BRT model for these variables. We are going to do an obviously wrong thing for the shake of being able to demonstrate how to fit a BRT model. In the next code you are going to repeat the same dataset multiple times:

```{r data repetition7}
modelDataSel <- rbind(modelDataSel, modelDataSel, modelDataSel, modelDataSel,
                      modelDataSel)
```

Now it is important to assess if the variables have the right categories. Variables should be type numeric or factor.

```{r check data7}
summary(modelDataSel)

# Two variables are character, we assign to factor instead:
modelDataSel$forestManagementType <- as.factor(modelDataSel$forestManagementType)

```

In the next step you can see how you can run the model with the selected variables and model parameters. You have a description of the models parameters in the @sec-modelBRT . In this example we are going to use the default parameters for the calibration, where learning rate = 0.01 and tree complexity = 1 and cross-validation = 10-fold. However, the bag fraction is changed from the default value, 0.75, to 0.5. As a family we used the Bernoulli family, because we are predicting presence/absence per plot. These data have 495 plots, comprising 290 presence records for the Eurasian treecreeper. You can check these numbers by doing:

```{r check numbers7}
table(modelDataSel$certhia)
```

As a first guess you could decide there are enough data to model interactions of reasonable complexity, and a lr of about 0.01 could be a reasonable starting point. You can use the model creation function that steps forward and identifies the optimal number of trees (nt) by doing this:

```{r BRTmodel7, message=FALSE, warning=FALSE, results = "hide"}
family <- "bernoulli"

    tc = 1    # tree complexity
    lr = 0.01 # learning rate-shrinkage 
    bag = 0.5 # bag fraction
    
    modelBRT <- dismo::gbm.step(data = modelDataSel,
                          #indices of predictor variables in data
                          gbm.x = 1:6, 
                          #index of response variable in data:
                          gbm.y = 7,  
                          family = family,
                          tree.complexity = tc,
                          learning.rate = lr,
                          bag.fraction = bag)  

```

Running a model such as that described above writes progress reports to the screen, makes a graph, and returns an object containing a number of components. The R console results reports a brief model summary all the values are also retained in the model object.

The model is built with the default 10-fold cross-validation (CV). In the plotted graph the solid black curve is the mean, and the dotted curves 1 standard error, for the changes in predictive deviance (i.e., as measured on the excluded folds of the CV). The red line shows the minimum of the mean, and the green line the number of trees at which that occurs. The final model that is returned in the model object is built on the full data set, using the number of trees identified as optimal.

Ideally, you should invest time in modifying the parameters and finr the parameters that provide the models with the minimum deviance resulting from the best combination of bag, tree complexity and learning rate values. For the shake of limited timing, we will only test here the default values.

#### Model behaviour

You can summarized the model parameters used and the cross validation statistics from the fitted model by doing this:

```{r BRTeval7}
# We make a table with the summary statistics  
 results <- data.frame(

# Model parameters
Tree.Complexity = modelBRT$gbm.call$tree.complexity, 
Learning.Rate = modelBRT$gbm.call$learning.rate, 
                 Bag.Fraction = modelBRT$gbm.call$bag.fraction,
                 Interaction.depth = modelBRT$interaction.depth,
                 Shrinkage = modelBRT$shrinkage,
                 N.trees = modelBRT$n.trees,
     
# Cross validation statistics 
     
## mean total deviance
Deviance = modelBRT$self.statistics$mean.resid, # mean residual deviance 

AUC = modelBRT$self.statistics$discrimination, # training data AUC score

Corr = modelBRT$self.statistics$correlation,   # training data correlation
                 
## Cross Validation statistics
                 
# We calculate each statistic within each fold (at the identified optimal number
# of trees that is calculated on the mean change in predictive deviance over all folds), 
#then present here the mean and standard error of those fold-based statistics.
                 
devianceCV = modelBRT$cv.statistics$deviance.mean,  # estimated cv deviance 
devianceCVse = modelBRT$cv.statistics$deviance.se,  # estimated cv deviance se
                 
CorrCV = modelBRT$cv.statistics$correlation.mean,  #cv correlation
CorrCVse = modelBRT$cv.statistics$correlation.se,  #cv correlation se
                 
AUCcv = modelBRT$cv.statistics$discrimination.mean, # cv AUC score
AUCcvSE = modelBRT$cv.statistics$discrimination.se)  # cv AUC score se
                
    
print(t(results))

```

#### Model output analysis

We can look at the relative contribution of each of the predictor variables. The measures are based on the number of time the variable is selected for splitting, weighted by the improvement of the model as a result of each split averaged across all trees. The relative contribution of each of the variables is scaled so the sum is 100%, with higher numbers indicating stronger influence in the response.

```{r varImportance7}
# Variables contribution 
modelBRT$contributions 

```

Here we can see that the two variables with the highest influence in the response are `GiniDBH` and `volAllhsa`.

Now we can evaluate the model behavior via partial dependence plots, showing the effect of each of the variables on the response by accounting for the average effects of all other predictors in the model:

```{r marginallEffects7}
    dismo::gbm.plot(modelBRT, n.plots = 6,
             plot.layout = c(2, 3), write.title = F)
```

In this partial dependence plots the predictions are on the scale of f(x). In this case, for the Bernoulli loss the returned value is on the log odds scale. You can see how this plot will look by plotting with the function from the package `gbm` and using the type "response". Since we are interesting in finding out if the forest density has an impact in the presence of the Eurasian treecreeper affected we can have a look to the plot density variable `volAllha` :

```{r, response7}
gbm::plot.gbm(modelBRT, i.var = 3, type = "response", ylab = "Probability of finding a Common redstart")
```

It seems that there is an increase in probability of finding a Eurasian treecreeper with higher forest densities. We could also analyse the interaction effects, of forest diversity and for example forest density. The model predictions can be obtained for each pair of predictor variables, setting all other predictors to their means.

To plot this pairwise interactions we have to do:

```{r pairwise int7, warning=FALSE, message=FALSE}
dismo::gbm.perspec(modelBRT, 3, 5)
```

It seems that the highes chances to see a Eurasian treecreeper is in dense forests with highest tree diversity.

### Question D - Group 4 {#sec-D_4}

-   Is the presence of the Eurasian treecreeper affected by forest management?

#### Fitting a BRT in R

In this case we want to assess the occurrence of certain species across the plots. In other words, we want to assess what is the probability of a certain species with biodiversity interest to be present in a plot based on the variables that describe the forest of that plot. In this case the response variable is `phoenicurus` that represents if the Great spotted woodpecker has been observed in this plot or not.

Then you need to select some variables of interest, after you have explored the data you can decide which variables you want to use to fit this model. We are proposing to select the following variables:

-   `latitude` as proxy for plot location or/and climate

-   `forestManagementType` to assess if different management types have different impact in the presence / absence of Parus major.

-   `volAllha` that is the total volume in the plot, as a proxy of how dense the plot is. Higher volumes will mean that the forest is more dense.

-   `GiniDBH` showing how homogeneous the plot is in trees diameters. A value closer to 1 will mean that indicate more structural heterogeneity, lower values indicate more homogeneous plots.

You can create a vector `selVar` in which you add the names of the selected variables. Then you only take those variables from the data that you will use to create the model.

```{r selectVar8}
# Select variables from the dataset for the model
selVar <- c("certhia", "latitude", "forestManagementType",
            "volAllha", "GiniDBH",  "ShannonIndexTreeSpp", 
            "Birds_rich")

# Filter the dataset to the selected variables
modelDataSel <- observations[, colnames(observations) %in% selVar]

```

Unfortunately the amount of that we have in this dataset it is not enough to fit a BRT model for these variables. We are going to do an obviously wrong thing for the shake of being able to demonstrate how to fit a BRT model. In the next code you are going to repeat the same dataset multiple times:

```{r data repetition8}
modelDataSel <- rbind(modelDataSel, modelDataSel, modelDataSel, modelDataSel,
                      modelDataSel)
```

Now it is important to assess if the variables have the right categories. Variables should be type numeric or factor.

```{r check data8}
summary(modelDataSel)

# Two variables are character, we assign to factor instead:
modelDataSel$forestManagementType <- as.factor(modelDataSel$forestManagementType)

```

In the next step you can see how you can run the model with the selected variables and model parameters. You have a description of the models parameters in the @sec-modelBRT . In this example we are going to use the default parameters for the calibration, where learning rate = 0.01 and tree complexity = 1 and cross-validation = 10-fold. However, the bag fraction is changed from the default value, 0.75, to 0.5. As a family we used the Bernoulli family, because we are predicting presence/absence per plot. These data have 495 plots, comprising 290 presence records for the Eurasian treecreeper. You can check these numbers by doing:

```{r check numbers8}
table(modelDataSel$certhia)
```

As a first guess you could decide there are enough data to model interactions of reasonable complexity, and a lr of about 0.01 could be a reasonable starting point. You can use the model creation function that steps forward and identifies the optimal number of trees (nt) by doing this:

```{r BRTmodel8, message=FALSE, warning=FALSE, results = "hide"}
family <- "bernoulli"

    tc = 1    # tree complexity
    lr = 0.01 # learning rate-shrinkage 
    bag = 0.5 # bag fraction
    
    modelBRT <- dismo::gbm.step(data = modelDataSel,
                          #indices of predictor variables in data
                          gbm.x = 1:6, 
                          #index of response variable in data:
                          gbm.y = 7,  
                          family = family,
                          tree.complexity = tc,
                          learning.rate = lr,
                          bag.fraction = bag)  

```

Running a model such as that described above writes progress reports to the screen, makes a graph, and returns an object containing a number of components. The R console results reports a brief model summary all the values are also retained in the model object.

The model is built with the default 10-fold cross-validation (CV). In the plotted graph the solid black curve is the mean, and the dotted curves 1 standard error, for the changes in predictive deviance (i.e., as measured on the excluded folds of the CV). The red line shows the minimum of the mean, and the green line the number of trees at which that occurs. The final model that is returned in the model object is built on the full data set, using the number of trees identified as optimal.

Ideally, you should invest time in modifying the parameters and finr the parameters that provide the models with the minimum deviance resulting from the best combination of bag, tree complexity and learning rate values. For the shake of limited timing, we will only test here the default values.

#### Model behaviour

You can summarized the model parameters used and the cross validation statistics from the fitted model by doing this:

```{r BRTeval8}
# We make a table with the summary statistics  
 results <- data.frame(

# Model parameters
Tree.Complexity = modelBRT$gbm.call$tree.complexity, 
Learning.Rate = modelBRT$gbm.call$learning.rate, 
                 Bag.Fraction = modelBRT$gbm.call$bag.fraction,
                 Interaction.depth = modelBRT$interaction.depth,
                 Shrinkage = modelBRT$shrinkage,
                 N.trees = modelBRT$n.trees,
     
# Cross validation statistics 
     
## mean total deviance
Deviance = modelBRT$self.statistics$mean.resid, # mean residual deviance 

AUC = modelBRT$self.statistics$discrimination, # training data AUC score

Corr = modelBRT$self.statistics$correlation,   # training data correlation
                 
## Cross Validation statistics
                 
# We calculate each statistic within each fold (at the identified optimal number
# of trees that is calculated on the mean change in predictive deviance over all folds), 
#then present here the mean and standard error of those fold-based statistics.
                 
devianceCV = modelBRT$cv.statistics$deviance.mean,  # estimated cv deviance 
devianceCVse = modelBRT$cv.statistics$deviance.se,  # estimated cv deviance se
                 
CorrCV = modelBRT$cv.statistics$correlation.mean,  #cv correlation
CorrCVse = modelBRT$cv.statistics$correlation.se,  #cv correlation se
                 
AUCcv = modelBRT$cv.statistics$discrimination.mean, # cv AUC score
AUCcvSE = modelBRT$cv.statistics$discrimination.se)  # cv AUC score se
                
    
print(t(results))

```

#### Model output analysis

We can look at the relative contribution of each of the predictor variables. The measures are based on the number of time the variable is selected for splitting, weighted by the improvement of the model as a result of each split averaged across all trees. The relative contribution of each of the variables is scaled so the sum is 100%, with higher numbers indicating stronger influence in the response.

```{r varImportance8}
# Variables contribution 
modelBRT$contributions 

```

Here we can see that the two variables with the highest influence in the response are `GiniDBH` and `volAllhsa`.

Now we can evaluate the model behavior via partial dependence plots, showing the effect of each of the variables on the response by accounting for the average effects of all other predictors in the model:

```{r marginallEffects8}
    dismo::gbm.plot(modelBRT, n.plots = 6,
             plot.layout = c(2, 3), write.title = F)
```

In this partial dependence plots the predictions are on the scale of f(x). In this case, for the Bernoulli loss the returned value is on the log odds scale. You can see how this plot will look by plotting with the function from the package `gbm` and using the type "response". Since we are interesting in finding out if the forest density has an impact in the presence of the Eurasian treecreeper affected we can have a look to the plot density variable `volAllha` :

```{r, response8}
gbm::plot.gbm(modelBRT, i.var = 2, type = "response", ylab = "Probability of finding a Common redstart")
```

It seems that there is a small difference in the probability of finding the Eurasian treecreeper different management strategies. We could also analyse the interaction effects, of forest diversity and forest structual diversity. The model predictions can be obtained for each pair of predictor variables, setting all other predictors to their means.

To plot this pairwise interactions we have to do:

```{r pairwise int8, warning=FALSE, message=FALSE}
dismo::gbm.perspec(modelBRT, 5, 4)
```

It seems that there are not clear pattenrs in the combined effect of forest structure diversity and forest tree species diversity.

# References
